{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyTimber_Tom, pagestore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import csv,glob, datetime, collections, time, subprocess,os, itertools\n",
    "\n",
    "from scipy import optimize as opt\n",
    "from scipy import constants as const\n",
    "from StringIO import StringIO\n",
    "from matplotlib import rc,rcParams\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from pandas import HDFStore \n",
    "from collections import namedtuple\n",
    "\n",
    "# simdata\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from pandas.tools.plotting import lag_plot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# check available diskspace\n",
    "# ---------------------------------------------------------------------------\n",
    "DiskUsage = namedtuple('DiskUsage','Total used free')\n",
    "def disk_usage(path):\n",
    "    st     = os.statvfs(path)\n",
    "    free   = st.f_bavail * st.f_frsize\n",
    "    total  = st.f_blocks * st.f_frsize\n",
    "    used   = (st.f_blocks - st.f_bfree) * st.f_frsize\n",
    "    return DiskUsage(total, used,free)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# fucntion to get a list of fills in a user defined time interval\n",
    "# ---------------------------------------------------------------------------\n",
    "def getfills(t1,t2):\n",
    "    db     = pytimber.LoggingDB()\n",
    "    fills  = db.get('HX:FILLN',t1,t2)\n",
    "    t,v    = fills['HX:FILLN']\n",
    "    df     = pd.DataFrame(np.vstack((t,v)).T,columns=['UnixTime','Fill'])\n",
    "    df['Timestamp'] = pd.to_datetime(df['UnixTime'],unit='s')\n",
    "    return df\n",
    "\n",
    "# --------------------\n",
    "# returns fill summary\n",
    "# --------------------\n",
    "def getsummary(fill):\n",
    "    db     = pytimber.LoggingDB()\n",
    "    if type(fill) == int:\n",
    "        try:\n",
    "            summary = db.getLHCFillData(fill)\n",
    "        except:\n",
    "            print 'Something went wrong no fill data loaded.'\n",
    "    else:\n",
    "        print 'Fillnumber needs to be integer ! Try again.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beamModes': [{'endTime': 1449365454.123,\n",
       "   'mode': u'SETUP',\n",
       "   'startTime': 1449364630.386},\n",
       "  {'endTime': 1449369654.556, 'mode': u'INJPROT', 'startTime': 1449365454.124},\n",
       "  {'endTime': 1449372698.952, 'mode': u'INJPHYS', 'startTime': 1449369654.557},\n",
       "  {'endTime': 1449374737.837, 'mode': u'INJPROT', 'startTime': 1449372698.953},\n",
       "  {'endTime': 1449375818.005, 'mode': u'INJPHYS', 'startTime': 1449374737.838},\n",
       "  {'endTime': 1449381701.018, 'mode': u'INJPHYS', 'startTime': 1449375818.006},\n",
       "  {'endTime': 1449382026.776, 'mode': u'PRERAMP', 'startTime': 1449381701.019},\n",
       "  {'endTime': 1449383254.726, 'mode': u'RAMP', 'startTime': 1449382026.777},\n",
       "  {'endTime': 1449383456.85, 'mode': u'FLATTOP', 'startTime': 1449383254.727},\n",
       "  {'endTime': 1449383857.318, 'mode': u'SQUEEZE', 'startTime': 1449383456.851},\n",
       "  {'endTime': 1449384644.837, 'mode': u'SQUEEZE', 'startTime': 1449383857.319},\n",
       "  {'endTime': 1449385433.245, 'mode': u'ADJUST', 'startTime': 1449384644.838},\n",
       "  {'endTime': 1449405157.208, 'mode': u'STABLE', 'startTime': 1449385433.246},\n",
       "  {'endTime': 1449405256.599,\n",
       "   'mode': u'BEAMDUMP',\n",
       "   'startTime': 1449405157.209},\n",
       "  {'endTime': 1449405581.084, 'mode': u'RAMPDOWN', 'startTime': 1449405256.6}],\n",
       " 'endTime': 1449405581.084,\n",
       " 'fillNumber': 4696,\n",
       " 'startTime': 1449363129.555}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = db.getLHCFillData(4696)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary.keys()\n",
    "sum2 = summary['beamModes']\n",
    "summary.pop('beamModes',None)\n",
    "# sum2.update(summary)\n",
    "summary['mode'] = summary.pop('fillNumber')\n",
    "sum2[:0] = [summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>mode</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.449406e+09</td>\n",
       "      <td>4696</td>\n",
       "      <td>1.449363e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.449365e+09</td>\n",
       "      <td>SETUP</td>\n",
       "      <td>1.449365e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.449370e+09</td>\n",
       "      <td>INJPROT</td>\n",
       "      <td>1.449365e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.449373e+09</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>1.449370e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.449375e+09</td>\n",
       "      <td>INJPROT</td>\n",
       "      <td>1.449373e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.449376e+09</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>1.449375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.449382e+09</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>1.449376e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.449382e+09</td>\n",
       "      <td>PRERAMP</td>\n",
       "      <td>1.449382e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.449383e+09</td>\n",
       "      <td>RAMP</td>\n",
       "      <td>1.449382e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.449383e+09</td>\n",
       "      <td>FLATTOP</td>\n",
       "      <td>1.449383e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.449384e+09</td>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>1.449383e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.449385e+09</td>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>1.449384e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.449385e+09</td>\n",
       "      <td>ADJUST</td>\n",
       "      <td>1.449385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.449405e+09</td>\n",
       "      <td>STABLE</td>\n",
       "      <td>1.449385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.449405e+09</td>\n",
       "      <td>BEAMDUMP</td>\n",
       "      <td>1.449405e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.449406e+09</td>\n",
       "      <td>RAMPDOWN</td>\n",
       "      <td>1.449405e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         endTime      mode     startTime\n",
       "0   1.449406e+09      4696  1.449363e+09\n",
       "1   1.449365e+09     SETUP  1.449365e+09\n",
       "2   1.449370e+09   INJPROT  1.449365e+09\n",
       "3   1.449373e+09   INJPHYS  1.449370e+09\n",
       "4   1.449375e+09   INJPROT  1.449373e+09\n",
       "5   1.449376e+09   INJPHYS  1.449375e+09\n",
       "6   1.449382e+09   INJPHYS  1.449376e+09\n",
       "7   1.449382e+09   PRERAMP  1.449382e+09\n",
       "8   1.449383e+09      RAMP  1.449382e+09\n",
       "9   1.449383e+09   FLATTOP  1.449383e+09\n",
       "10  1.449384e+09   SQUEEZE  1.449383e+09\n",
       "11  1.449385e+09   SQUEEZE  1.449384e+09\n",
       "12  1.449385e+09    ADJUST  1.449385e+09\n",
       "13  1.449405e+09    STABLE  1.449385e+09\n",
       "14  1.449405e+09  BEAMDUMP  1.449405e+09\n",
       "15  1.449406e+09  RAMPDOWN  1.449405e+09"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsum = pd.DataFrame.from_dict(sum2)\n",
    "dfsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# returns fill summary\n",
    "# --------------------\n",
    "def getsummary(self):\n",
    "        # check if already present in hdf file\n",
    "        if '/summary' in hdffill.keys():\n",
    "            dfsummary = hdffill['/summary']\n",
    "        else:\n",
    "            infn   = \"Fill\" + str(self.fillnumber) + \"Summary\"\n",
    "            bashcmd1 = \"./cern-ldb -M FD -fn \" + str(self.fillnumber) + \" -N  \" + infn + \" -F CSV\"\n",
    "            bashcmd2 = \"rm \" + infn + \".CSV \"\n",
    "            subprocess.call(bashcmd1,shell=True)\n",
    "            subprocess.call(bashcmd2,shell=True)\n",
    "            dfsummary = pd.read_csv(infn + \".CSV\",delimiter=',',header=0)\n",
    "            hdffill.put('summary',dfsummary,format='table')\n",
    "        return dfsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LHCfill(object):\n",
    "    # path to file with horizontal bpm names,etc\n",
    "    timbernames = '/afs/cern.ch/user/t/tomerten/public/timbernames.h5'\n",
    "    hdftimbernames = HDFStore(timbernames)\n",
    "    \n",
    "    # names of timberdata we want to extract\n",
    "    timbervarFBCTB1    = 'LHC.BCTFR.A6R4.B1:BUNCH_INTENSITY'\n",
    "    timbervarFBCTB2    = 'LHC.BCTFR.A6R4.B2:BUNCH_INTENSITY'\n",
    "\n",
    "    timbervarBQMB1L    = 'LHC.BQM.B1:BUNCH_LENGTHS'\n",
    "    timbervarBQMB1F    = 'LHC.BQM.B1:FILLED_BUCKETS'\n",
    "\n",
    "    timbervarBQMB2L    = 'LHC.BQM.B2:BUNCH_LENGTHS'\n",
    "    timbervarBQMB2F    = 'LHC.BQM.B2:FILLED_BUCKETS'\n",
    "\n",
    "    timbervarBSRTB1H   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_H'\n",
    "    timbervarBSRTB1V   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_V'\n",
    "    timbervarBSRTB1GD  = 'LHC.BSRT.5R4.B1:GATE_DELAY'\n",
    "    timbervarBSRTB1CH  = 'LHC.BSRT.5R4.B1:LSF_H'\n",
    "    timbervarBSRTB1CV  = 'LHC.BSRT.5R4.B1:LSF_V'\n",
    "\n",
    "    timbervarBSRTB2H   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_H'\n",
    "    timbervarBSRTB2V   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_V'\n",
    "    timbervarBSRTB2GD  = 'LHC.BSRT.5L4.B2:GATE_DELAY'\n",
    "    timbervarBSRTB2CH  = 'LHC.BSRT.5L4.B2:LSF_H'\n",
    "    timbervarBSRTB2CV  = 'LHC.BSRT.5L4.B2:LSF_V'\n",
    "\n",
    "    timbervarLumiAtlas = \"ATLAS:LUMI_TOT_INST\"\n",
    "    timbervarLumiAlice = \"ALICE:LUMI_TOT_INST\"\n",
    "    timbervarLumiCMS   = \"CMS:LUMI_TOT_INST\"\n",
    "    timbervarLumiLHCB  = \"LHCB:LUMI_TOT_INST\"\n",
    "    \n",
    "    timbervarhorbpm    = 'LHC.BOFSU:POSITIONS_H'\n",
    "    \n",
    "    fillkeys = ['/summary',\n",
    "                '/bpmhor/bpmdata',\n",
    "                '/bpmhor/bpmmask',\n",
    "                 '/bunchintensity/b1',\n",
    "                 '/bunchintensity/b1pos',\n",
    "                 '/bunchintensity/b2',\n",
    "                 '/bunchintensity/b2pos',\n",
    "                 '/bunchlenght/b1',\n",
    "                 '/bunchlenght/b1pos',\n",
    "                 '/bunchlenght/b2',\n",
    "                 '/bunchlenght/b2pos',\n",
    "                 '/emit/ex1',\n",
    "                 '/emit/ex2',\n",
    "                 '/emit/ey1',\n",
    "                 '/emit/ey2',\n",
    "                 '/lumi/alice',\n",
    "                 '/lumi/atlas',\n",
    "                 '/lumi/cms',\n",
    "                 '/lumi/lhcb']\n",
    "    # constants\n",
    "    protonmass = const.physical_constants['proton mass energy equivalent in MeV'][0]/1000 # GeV\n",
    "    ionA       = 208.\n",
    "    ionZ       = 82.\n",
    "    energy     = 6370\n",
    "    gamma      = energy * ionZ / 193.7291748489224\n",
    "\n",
    "    # beta's for the undulators and dipoles for the bsrt light\n",
    "    betaUndH = [203.,200.]\n",
    "    betaUndV = [318.,327.]\n",
    "    betaDipH = [214., 205.]\n",
    "    betaDipV = [328.,344.]\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    # initialization :\n",
    "    # ----------------\n",
    "    # fillnumber                : int\n",
    "    # basedir                   : string\n",
    "    # summarydf                 : pandas dataframe\n",
    "    # bunchlenb1df,bunchlenb1df : pandas dataframe\n",
    "    # ex1df,ey1df,ex2df,ey2df   : pandas dataframe\n",
    "    # I1df, I2df                : pandas dataframe\n",
    "    # lumiatlasdf,lumicmsdf,lumialicedf,lumilhcbdf : pandas dataframe\n",
    "    # bpmhdf                    : pandas dataframe\n",
    "    # bpmhmask                  : pandas dataframe\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def __init__(self,fillnumber,basedir):\n",
    "        # creating/opening hdf5 file for retreiving or appending data\n",
    "        fillfn         = basedir + str(fillnumnber) + '.h5'\n",
    "        hdffill        = HDFStore(fillfn)\n",
    "                \n",
    "        self.fillnumber = fillnumber\n",
    "        self.basedir    = basedir\n",
    "        \n",
    "        self.summary    = self.getsummary()\n",
    "        \n",
    "        self.bunchlenb1df, self.bunch2enb1df = self.getbunchlenghts('Fill' + str(self.fillnumber) + 'BLb1',\n",
    "                                                                    'Fill' + str(self.fillnumber) + 'BLb2')\n",
    "        \n",
    "        self.ex1df,self.ey1df,self.ex2df,self.ey2df = self.getemitbsrt('Fill' + str(self.fillnumber) +'emit1',\n",
    "                                                                       'Fill' + str(self.fillnumber)+'emit2') \n",
    "        \n",
    "        self.I1df,self.I2df                         = self.getFBCT('Fill' + str(self.fillnumber) +'fbct1',\n",
    "                                                                   'Fill' + str(self.fillnumber)+'fbct2')\n",
    "        \n",
    "        self.lumiatlasdf,self.lumicmsdf,self.lumialicedf,self.lumilhcbdf = self.getlumi('Fill' + \n",
    "                                                                                        str(self.fillnumber) +\n",
    "                                                                                        'atlas','Fill' + \n",
    "                                                                                        str(self.fillnumber)+\n",
    "                                                                                        'cms',\n",
    "                                                                                        'Fill' + \n",
    "                                                                                        str(self.fillnumber) +\n",
    "                                                                                        'alice','Fill' +\n",
    "                                                                                        str(self.fillnumber)+\n",
    "                                                                                        'lhcb')\n",
    "        self.bpmhdf    = self.gethorbpm('Fill' + str(self.fillnumber) +'bpmH')\n",
    "        self.bpmhmask  = self.gethorbpmmask('bpmhmask' + str(self.fillnumber))\n",
    "      \n",
    "    # -----------------------------------\n",
    "    # simplified timber download function\n",
    "    # -----------------------------------\n",
    "    def download(start,stop,timbervar,fn=None,fixed=None,cols=None):\n",
    "        bashcmd = './cern-ldb -vs ' + var + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +\\\n",
    "                            stop + '\\\" -N ' + 'fn' + ' -F CSV'\n",
    "        try:\n",
    "            subprocess.call(bashcmd,shell=True)\n",
    "        except:\n",
    "            print 'Loading of data failed.'\n",
    "            \n",
    "        if fixed == None:  \n",
    "            if cols == None:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2])\n",
    "            else:\n",
    "                 df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],usecols=cols)\n",
    "        else:\n",
    "            if cols == None:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],names=fixed)\n",
    "            else:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],names=fixed,usecols=cols)\n",
    "        \n",
    "        if fn == None:\n",
    "            subprocess.call('rm fn.CSV',shell=True)\n",
    "            return df\n",
    "        else:\n",
    "            if type(fn)== str:\n",
    "                subprocess.call('mv fn.CSV ' + fn ,shell=True)\n",
    "                return fn\n",
    "            else:\n",
    "                print 'invalid filename'\n",
    "                return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------\n",
    "    # def convert to unix time\n",
    "    # -------------------------\n",
    "    def converttimetounix(self,t):\n",
    "        return time.mktime(datetime.datetime.strptime(t,\"%Y-%m-%d %H:%M:%S.%f\").timetuple())\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # function for adding times in YY-mm-dd HH:MM:SS.fff format\n",
    "    # ---------------------------------------------------------\n",
    "    def addtime(self,intime,deltahour):\n",
    "        mytime = datetime.datetime.strptime(intime,\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        mytime += datetime.timedelta(hours=deltahour)\n",
    "        return mytime.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # returns dict with start stop times of modes in a fill\n",
    "    # ---------------------------------------------------------\n",
    "    def gettimes(self):\n",
    "        timesodic = collections.OrderedDict()\n",
    "        if '/summary' in hdffill.keys():\n",
    "            dfsummary = hdffill['/summary']\n",
    "            dc = collections.OrderedDict()\n",
    "            for name, group in dfsummary.groupby('Value'):\n",
    "                starttimes = group['StartTime(UTC_TIME)'].values\n",
    "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
    "                arr = np.array([starttimes,stoptimes])\n",
    "                dc[name] = np.transpose(arr)\n",
    "            return dc\n",
    "        else:\n",
    "            dfsummary = self.getsummary()\n",
    "            dc = collections.OrderedDict()\n",
    "            for name, group in dfsummary.groupby('Value'):\n",
    "                starttimes = group['StartTime(UTC_TIME)'].values\n",
    "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
    "                arr = np.array([starttimes,stoptimes])\n",
    "                dc[name] = np.transpose(arr)\n",
    "            return dc\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # returns arrays with the bunch slots\n",
    "    # ---------------------------------------------------------\n",
    "    def getbunchpositions(self):\n",
    "        # get beginning and end of fill\n",
    "        tdc = self.gettimes()\n",
    "        # check if data already present\n",
    "        if (('/bunchlenght/b1pos' in hdffill.keys()) & ('/bunchlenght/b2pos' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchpos = hfdfill['/bunchlenght/b1pos']\n",
    "                b2bunchpos = hdffill['/bunchlenght/b2pos']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "        else:\n",
    "            # if data not present download and transform in dataframe + store \n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            b1bunchpos = self.download(start,stop,self.timbervarBQMB1F)\n",
    "            b2bunchpos = self.download(start,stop,self.timbervarBQMB2F)\n",
    "            \n",
    "            # write to hdf \n",
    "            hdffill.put('/bunchlenght/b1pos',b1bunchpos.astype(int))\n",
    "            hdffill.put('/bunchlenght/b2pos',b2bunchpos.astype(int))\n",
    "\n",
    "        \n",
    "        return [int((i-1.)/10.) for i in b1bunchpos.drop(0,axis=1)[b1bunchpos.drop(0,axis=1).sum(axis=1).values>0].tail(1).values[0] if i >0],\\\n",
    "            [int((i-1.)/10.) for i in b2bunchpos.drop(0,axis=1)[b2bunchpos.drop(0,axis=1).sum(axis=1).values>0].tail(1).values[0] if i >0]\n",
    "       \n",
    "    # ---------------------------------------------------------\n",
    "    # returns the bunch lengths \n",
    "    # ---------------------------------------------------------\n",
    "    def getbunchlenghts(self):\n",
    "        tdc = self.gettimes()\n",
    "        # check if data already present\n",
    "        if (('/bunchlenght/b1' in hdffill.keys()) & ('/bunchlenght/b2' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchdata = hfdfill['/bunchlenght/b1']\n",
    "                b2bunchdata = hdffill['/bunchlenght/b2']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            b1bunchdata = self.download(start,stop,self.timbervarBQMB1L)\n",
    "            b2bunchdata = self.download(start,stop,self.timbervarBQMB2L)\n",
    " \n",
    "            bposb1, bposb2 = self.getbunchpositions()\n",
    "            bposb1[:0]=[0]\n",
    "            bposb2[:0]=[0]\n",
    "        return b1bunchdata[bposb1],b2bunchdata[bposb2]\n",
    "        \n",
    "    \n",
    "    def convertdicttodf(self,dictin):\n",
    "        dflist        = [pd.DataFrame(np.array(dictin[i]),columns=[0,i]) for i in dictin.keys()]\n",
    "        dflistgrouped = [dflist[i].groupby(0,as_index=False).mean() for i in range(len(dflist))]\n",
    "        dffinal       = reduce(lambda left,right: pd.merge(left,right,on=0,how='outer'),dflistgrouped)\n",
    "        dffinal2      = dffinal.fillna(0)\n",
    "        cols          = dffinal.columns\n",
    "        return dffinal2.loc[(dffinal2[cols[1:]]!=0).any(1)]\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # getting bsrt data\n",
    "    # ---------------------------------------------------------\n",
    "    def getemitbsrt(self):\n",
    "        if (('/emit/ex1' in hdffill.keys()) & \n",
    "            ('/emit/ey1' in hdffill.keys()) &\n",
    "            ('/emit/ex2' in hdffill.keys()) & \n",
    "            ('/emit/ey2' in hdffill.keys())):\n",
    "            ex1dfout = hdffill['/emit/ex1']\n",
    "            ey1dfout = hdffill['/emit/ey1']\n",
    "            ex2dfout = hdffill['/emit/ex2']\n",
    "            ey2dfout = hdffill['/emit/ey2']\n",
    "        else:\n",
    "            tdc = self.gettimes()\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            try:\n",
    "                # downloading the files\n",
    "                # +++++++++++++++++++++\n",
    "                \n",
    "                fgdb1   = self.download(start,stop,self.timbervarBSRTB1GD,fixed=range(200))\n",
    "                fsighb1 = self.download(start,stop,self.timbervarBSRTB1H,fixed=range(200))\n",
    "                fsigvb1 = self.download(start,stop,self.timbervarBSRTB1V,fixed=range(200))\n",
    "\n",
    "                fgdb1   = self.download(start,stop,self.timbervarBSRTB2G,fixed=range(200))\n",
    "                fsighb1 = self.download(start,stop,self.timbervarBSRTB2H,fixed=range(200))\n",
    "                fsigvb1 = self.download(start,stop,self.timbervarBSRTB2V,fixed=range(200))\n",
    "\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "                \n",
    "            # transforming sigma to emit\n",
    "            # ++++++++++++++++++++++++++\n",
    "            fgdb1conv  = fgdb1.fillna(value=0).astype(int)\n",
    "            bunchesb1  = fgdb1conv.drop(0,axis=1).as_matrix()\n",
    "            bunchsetb1 = set(bunches.flatten())\n",
    "            dfex1b1       = pd.DataFrame()\n",
    "            dfey1b1       = pd.DataFrame()\n",
    "            \n",
    "            for b in bunchsetb1:\n",
    "                bunchmask   = (fgdb1conv==b)\n",
    "                hor         = fsighb1.where(bunchmask)\n",
    "                ver         = fsigvb1.where(bunchmask)\n",
    "                hortempdf      = pd.DataFrame()\n",
    "                hortempdf['t'] = pd.Series(fsighb1.iloc[hor.mean().dropna().index][0])\n",
    "                hortempdf[b]   = hor.mean().dropna()\n",
    "                vertempdf      = pd.DataFrame()\n",
    "                vertempdf['t'] = pd.Series(fsigvb1.iloc[ver.mean().dropna().index][0])\n",
    "                vertempdf[b]   = ver.mean().dropna()\n",
    "                dfex1b1        = dfex1b1.append(hortempdf)\n",
    "                dfey1b1        = dfey1b1.append(vertempdf)\n",
    "                \n",
    "            fgdb2conv  = fgdb2.fillna(value=0).astype(int)\n",
    "            bunchesb2  = fgdb2conv.drop(0,axis=1).as_matrix()\n",
    "            bunchsetb2 = set(bunches.flatten())\n",
    "            dfex2b2       = pd.DataFrame()\n",
    "            dfey2b2       = pd.DataFrame()\n",
    "            \n",
    "            for b in bunchsetb2:\n",
    "                bunchmask   = (fgdb2conv==b)\n",
    "                hor         = fsighb2.where(bunchmask)\n",
    "                ver         = fsigvb2.where(bunchmask)\n",
    "                hortempdf      = pd.DataFrame()\n",
    "                hortempdf['t'] = pd.Series(fsighb2.iloc[hor.mean().dropna().index][0])\n",
    "                hortempdf[b]   = hor.mean().dropna()\n",
    "                vertempdf      = pd.DataFrame()\n",
    "                vertempdf['t'] = pd.Series(fsigvb2.iloc[ver.mean().dropna().index][0])\n",
    "                vertempdf[b]   = ver.mean().dropna()\n",
    "                dfex2b2        = dfex2b2.append(hortempdf)\n",
    "                dfey2b2        = dfey2b2.append(vertempdf)\n",
    "  \n",
    "            # get end of ramp for switching betas\n",
    "            # +++++++++++++++++++++++++++++++++++\n",
    "            rampend = tdc['RAMP'][-1][-1]\n",
    "            rampend = self.converttimetounix(rampend)\n",
    "\n",
    "            dfex1b1set = dfex1b1.set_index('t')\n",
    "            dfey1b1set = dfey1b1.set_index('t')\n",
    "            dfex2b2set = dfex1b1.set_index('t')\n",
    "            dfey2b2set = dfex1b1.set_index('t')\n",
    "            \n",
    "            \n",
    "            dfex1b1set[dfex1b1set.index>rampend] = \\\n",
    "                dfex1b1set[dfex1b1set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipH[0])\n",
    "            dfex1b1set[dfex1b1set.index<=rampend] = \\\n",
    "                dfex1b1set[dfex1b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndH[0])\n",
    "            dfey1b1set[dfey1b1set.index>rampend] = \\\n",
    "                dfey1b1set[dfey1b1set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipV[1])\n",
    "            dfey1b1set[dfey1b1set.index<=rampend] = \\\n",
    "                dfey1b1set[dfey1b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndV[1])\n",
    "                \n",
    "            dfex2b2set[dfex2b2set.index>rampend] = \\\n",
    "                dfex2b2set[dfex2b2set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipH[0])\n",
    "            dfex2b2set[dfex2b2set.index<=rampend] = \\\n",
    "                dfex2b2set[d2ex2b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndH[0])\n",
    "            dfey2b2set[dfey2b2set.index>rampend] = \\\n",
    "                dfey2b2set[dfey2b2set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipV[1])\n",
    "            dfey2b2set[dfey2b2set.index<=rampend] = \\\n",
    "                dfey2b2set[dfey2b2set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndV[1])\n",
    "                \n",
    "            # writing to disc and return result\n",
    "            # +++++++++++++++++++++++++++++++++++  \n",
    "            ex1dfout = dfex1b1set.reset_index()\n",
    "            ey1dfout = dfey1b1set.reset_index()\n",
    "            ex2dfout = dfex2b2set.reset_index()\n",
    "            ey2dfout = dfey2b2set.reset_index()\n",
    "            hdffill['/emit/ex1'] = ex1dfout\n",
    "            hdffill['/emit/ey1'] = ey1dfout\n",
    "            hdffill['/emit/ex2'] = ex2dfout\n",
    "            hdffill['/emit/ey2'] = ey2dfout\n",
    "            \n",
    "                \n",
    "        return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
    "     \n",
    "    # ---------------------------------------------------------\n",
    "    # getting FBCT data\n",
    "    # ---------------------------------------------------------\n",
    "    def getFBCT(self):\n",
    "        tdc = self.gettimes()\n",
    "    \n",
    "        cols1,cols2 = self.getbunchpositions()\n",
    "        cols1 = [i + 1 for i in cols1]\n",
    "        cols2 = [i + 1 for i in cols2]\n",
    "        cols1[:0] = [0]\n",
    "        cols2[:0] = [0]\n",
    "        \n",
    "        # if data exist reload\n",
    "        # ++++++++++++++++++++\n",
    "        if (('/bunchintensity/b1' in hdffill.keys()) & ('/bunchintensity/b2' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchdata = hfdfill['/bunchintensity/b1']\n",
    "                b2bunchdata = hdffill['/bunchintensity/b2']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "                \n",
    "        # if data not present download\n",
    "        # ++++++++++++++++++++++++++++\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            try:\n",
    "                b1bunchdata = self.download(start,stop,self.timbervarFBCTB1,fixed=range(3565),cols=cols1)\n",
    "                b2bunchdata = self.download(start,stop,self.timbervarFBCTB2,fixed=range(3565),cols=cols2)\n",
    "                b1bunchdata.columns = [i-1 if i !=0 else 0 for i in cols1]\n",
    "                b2bunchdata.columns = [i-1 if i !=0 else 0 for i in cols2]\n",
    "                b1bunchdata.to_csv(outfn1,index=None)\n",
    "                b2bunchdata.to_csv(outfn2,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "                \n",
    "            hfdfill['/bunchintensity/b1'] = b1bunchdata\n",
    "            hdffill['/bunchintensity/b2'] = b2bunchdata\n",
    "            \n",
    "        return b1bunchdata,b2bunchdata\n",
    "       \n",
    "    # ---------------------------------------------------------\n",
    "    # getting lumi data\n",
    "    # ---------------------------------------------------------\n",
    "    def getlumi(self):\n",
    "        tdc = self.gettimes()\n",
    "           \n",
    "        if (('/lumi/alice' in hdffill.keys()) &\n",
    "            ('/lumi/atlas' in hdffill.keys()) &\n",
    "            ('/lumi/cms' in hdffill.keys()) &\n",
    "            ('/lumi/lhcb' in hdffill.keys())):\n",
    "            atlaslumidata = hfdfill['/lumi/alice']\n",
    "            cmslumidata   = hfdfill['/lumi/atlas']\n",
    "            alicelumidata = hfdfill['/lumi/cms']\n",
    "            lhcblumidata  = hfdfill['/lumi/lhcb']\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            atlaslumidata = self.download(start,stop,self.timbervarLumiAtlas)\n",
    "            cmslumidata   = self.download(start,stop,self.timbervarLumiCMS)\n",
    "            alicelumidata = self.download(start,stop,self.timbervarLumiAlice)\n",
    "            lhcblumidata  = self.download(start,stop,self.timbervarLumiLHCB)\n",
    "            \n",
    "            atlaslumidata.columns = ['t','L']\n",
    "            cmslumidata.columns   = ['t','L']\n",
    "            alicelumidata.columns = ['t','L']\n",
    "            lhcblumidata.columns  = ['t','L']\n",
    "                   \n",
    "        return atlaslumidata,cmslumidata,alicelumidata,lhcblumidata\n",
    "    \n",
    "    def gethorbpm(self,fn):\n",
    "        tdc = self.gettimes()\n",
    "        fileexist = False\n",
    "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
    "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
    "            fileexist = True\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            bashcmdhorbpm = './cern-ldb -vs ' +  self.timbervarhorbpm + ' -t1 \\\"' + start +\\\n",
    "                            '\\\" -t2 \\\"' + stop + '\\\" -sa REPEAT -ss 5 -si MINUTE -N ' + fn + ' -F CSV'\n",
    "            try:\n",
    "                subprocess.call(bashcmdhorbpm,shell=True)\n",
    "                fileexist = True\n",
    "                bashcmd1 = \"mv \" + fn +  \".CSV \" + outfn\n",
    "                subprocess.call(bashcmd1,shell=True)\n",
    "                \n",
    "                bpmdata = pd.read_csv(outfn,delimiter=',',header=None,\n",
    "                                          skiprows=[0,1,2])\n",
    "                bpmdata.to_csv(outfn,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "        if fileexist:\n",
    "            df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
    "            colnames = list(df.columns[1:])\n",
    "            colnames[:0] =['t']\n",
    "            bpmdata = pd.read_csv(outfn,names=colnames,skiprows=[0])\n",
    "            return bpmdata\n",
    "        else:\n",
    "            print 'Something went wrong no data loaded.'\n",
    "            return 0\n",
    "        \n",
    "    def gethorbpmmask(self,fn):\n",
    "        tdc = self.gettimes()\n",
    "        fileexist = False\n",
    "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
    "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
    "            fileexist = True\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_MASK_H' + ' -t1 \\\"' + start +\\\n",
    "                            '\\\" -t2 \\\"'  + stop + '\\\" -N ' + 'bpmhmask' + str(self.fillnumber) + ' -F CSV'\n",
    "            try:\n",
    "                subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "                fileexist = True\n",
    "                bashcmd1 = \"mv \" + 'bpmhmask'+ str(self.fillnumber) + \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhmask'+ str(self.fillnumber) + '.csv'\n",
    "                subprocess.call(bashcmd1,shell=True)\n",
    "                dfmask = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
    "                dfmask.to_csv(outfn,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "        if fileexist:\n",
    "            df = pd.read_csv(outfn,skiprows=[0,1,2])\n",
    "            bpmdata = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
    "            return bpmdata\n",
    "        else:\n",
    "            print 'Something went wrong no data loaded.'\n",
    "            return 0\n",
    "        \n",
    "    def getbpmhreduced(self):\n",
    "        dfmask = self.bpmhmask\n",
    "\n",
    "        # selecting the last non-zero row of the maskfile to use as a mask on the bpm data\n",
    "        # not the best way but does the job for the moment\n",
    "        # problem to unequal shape of mask and data dataframes\n",
    "        dfcopy = pd.DataFrame(dfmask[range(1,1089)][dfmask[range(1,1089)].sum(axis=1).values>1.].tail(1).values, \n",
    "                              columns =  self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1).columns)\n",
    "\n",
    "        # taking the bpm data but removing the timestamps in order to be able to apply a mask\n",
    "        dffff = self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1)\n",
    "        selection = dffff * dfcopy.iloc[0]\n",
    "        selectionred= selection[(selection>1.0)| (selection< -1.0)].dropna(axis=1,how='all')\n",
    "        return selectionred\n",
    "    \n",
    "    def transformbpmdata(self,tfslhcb1,tfslhcb2,ipnr=5):\n",
    "        selectionred = self.getbpmhreduced()\n",
    "        # selecting the BPM around the desired ip (pandas dataframes)\n",
    "        bpmrtest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R' + str(ipnr)\n",
    "                                                                                                   + '.B1')])]\n",
    "        bpmltest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L' + str(ipnr)\n",
    "                                                                                                   + '.B2')])]\n",
    "        # adding the s positions of these BPMs for plotting\n",
    "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
    "        colsb1 = list(tfsb1.columns[1:])\n",
    "\n",
    "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "\n",
    "        tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R' + str(ipnr) + '.B1'))]\n",
    "        tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "        tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "\n",
    "        namesr = list(bpmrtest.columns)\n",
    "\n",
    "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb2 = tfsb2[tfsb2['NAME']!='%s']\n",
    "        colsb2 = list(tfsb2.columns[1:])\n",
    "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
    "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
    "        tfsbpml = tfsb2[(tfsb2['NAME'].str.contains('BPM')) & (tfsb2['NAME'].str.contains('L' + str(ipnr) + '.B2'))]\n",
    "        tfsbpml = tfsbpml[1:]\n",
    "        tfsbpml = tfsbpml[['NAME','S']]\n",
    "\n",
    "        namesl = list(bpmltest.columns)\n",
    "\n",
    "        return bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr\n",
    "    \n",
    "    def plotbpm(self,tfslhcb1,tfslhcb2,ipnr=5,nn=50,step=20,xmin=0,xmax=600):\n",
    "        bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr = self.transformbpmdata(\n",
    "                                                    tfslhcb1,\n",
    "                                                    tfslhcb2,\n",
    "                                                    ipnr=ipnr\n",
    "                                                   )\n",
    "        from IPython.html.widgets import FloatProgress\n",
    "        from IPython.display import display\n",
    "        f = FloatProgress(min=0,max=2*nn/float(step))\n",
    "        display(f)\n",
    "\n",
    "        error = False\n",
    "\n",
    "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
    "        colsb1 = list(tfsb1.columns[1:])\n",
    "\n",
    "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "        sipb1 = tfsb1[tfsb1['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
    "\n",
    "        tfsb2  = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb2  = tfsb2[tfsb2['NAME']!='%s']\n",
    "        colsb2 = list(tfsb2.columns[1:])\n",
    "\n",
    "        tfsb2 = pd.read_csv(tfslhcb2, skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
    "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
    "        sipb2 = tfsb2[tfsb2['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
    "\n",
    "        tfsbpmr['S'] = tfsbpmr['S'].apply(lambda x: float(x)-float(sipb1))\n",
    "        tfsbpml['S'] = tfsbpml['S'].apply(lambda x: float(x)-float(sipb2))\n",
    "\n",
    "    #     print tfsbpmr\n",
    "\n",
    "        fig = plt.figure(figsize=(18,20))\n",
    "        ax  = fig.add_subplot(211)\n",
    "\n",
    "        s1   = np.array([float(tfsbpml[tfsbpml['NAME']==n]['S'].values[0]) for n in namesl])\n",
    "        max1 = len(bpmltest)\n",
    "\n",
    "\n",
    "        for i in range(0,len(bpmltest.tail(nn)),step):\n",
    "            try:\n",
    "                data = np.array([bpmltest[n][max1-nn+i] for n in namesl])\n",
    "                plt.scatter(s1,data)\n",
    "                plt.plot(s1,data)\n",
    "                f.value = i\n",
    "            except:\n",
    "                print 'nn out of range'\n",
    "                error = True\n",
    "                break\n",
    "\n",
    "\n",
    "    #     plt.plot((0,500),(500,500),'k-')\n",
    "    #     plt.plot((0,500),(-500,-500),'k-')\n",
    "    #     plt.plot((0,500),(-3000,-3000),'k-')\n",
    "    #     plt.plot((0,500),(-3500,-3500),'k-')\n",
    "    #     plt.plot((0,500),(0,0),'k-')\n",
    "        plt.grid()\n",
    "        plt.xlim(xmin,xmax)\n",
    "        plt.ylim(-5000,5000)\n",
    "\n",
    "        ax.set_xticks(np.arange(xmin,xmax,100))\n",
    "        ax.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
    "        ax.set_yticks(np.arange(-5000,5000,2000))\n",
    "        ax.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
    "        ax.grid(which='minor',alpha=0.65)\n",
    "\n",
    "        plt.xlabel('s',fontsize=16.0)\n",
    "        plt.ylabel('x [um]')\n",
    "        plt.title('BPM orbits Horizontal left of ' + str(ipnr) + ' - fill ' + str(LHCfill.fillnumber))\n",
    "\n",
    "    #     ax.text(100,4000, 'Each line (colour) is at a different timestamp.')\n",
    "\n",
    "    #     ax.annotate('roughly 0.5 mm below \\n 3mm from bump',xy=(440,-3400),xytext=(400,-5000),\n",
    "    #                 arrowprops=dict(facecolor='red',shrink=0.5))\n",
    "\n",
    "    #     ax.plot([440],[500],'o')\n",
    "\n",
    "    #     ax.annotate('Expected with 0.5 mm bump',xy=(440,500),xytext=(400,2500),\n",
    "    #                 arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "        ax2  = fig.add_subplot(2,1,2)\n",
    "        max2 = len(bpmrtest)\n",
    "        s2   = np.array([float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]) for n in namesr])\n",
    "\n",
    "        for i in range(0,len(bpmrtest.tail(nn)),step):\n",
    "            try:\n",
    "                data =  np.array([bpmrtest[n][max2-nn+i] for n in namesr])\n",
    "                ax2.scatter(s2,data)\n",
    "                ax2.plot(s2,data)\n",
    "                f.value = f.value +1 \n",
    "            except:\n",
    "                print 'nn out of range'\n",
    "                error = True\n",
    "                break\n",
    "        if error:\n",
    "            print 'No valid plot generated'\n",
    "        else:\n",
    "    #         plt.plot((0,500),(500,500),'k-')\n",
    "    #         plt.plot((0,500),(-500,-500),'k-')\n",
    "    #         plt.plot((0,500),(-3000,-3000),'k-')\n",
    "    #         plt.plot((0,500),(-3500,-3500),'k-')\n",
    "    #         plt.plot((0,500),(0,0),'k-')\n",
    "            plt.grid()\n",
    "            plt.xlim(xmin,xmax)\n",
    "            plt.ylim(-5000,5000)\n",
    "\n",
    "            ax2.set_xticks(np.arange(xmin,xmax,100))\n",
    "            ax2.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
    "            ax2.set_yticks(np.arange(-5000,5000,2000))\n",
    "            ax2.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
    "\n",
    "            ax2.grid(which='minor',alpha=0.65)\n",
    "    #         ax2.annotate('roughly 0.5 mm above \\n 3mm from bump',xy=(433,-2650),xytext=(400,-5000),\n",
    "    #                     arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "            plt.xlabel('s',fontsize=16.0)\n",
    "            plt.ylabel('x [um]')\n",
    "            plt.title('BPM orbits Horizontal right of ' + str(ipnr) + '  - fill ' + str(LHCfill.fillnumber) )\n",
    "\n",
    "            plt.show()\n",
    "            print f.value\n",
    "            # plt.savefig('Fill4707IP5bpm.png',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9216000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,used,free =disk_usage('.')\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'LHC.BOFSU:BPM_CAL_DAB_TEMP',\n",
       " u'LHC.BOFSU:BPM_CAL_DATA_VALID',\n",
       " u'LHC.BOFSU:BPM_CAL_MAPPING_ERRORS',\n",
       " u'LHC.BOFSU:BPM_CAL_NB_BUNCHES_HS_B1',\n",
       " u'LHC.BOFSU:BPM_CAL_NB_BUNCHES_HS_B2',\n",
       " u'LHC.BOFSU:BPM_CAL_NB_BUNCHES_LS_B1',\n",
       " u'LHC.BOFSU:BPM_CAL_NB_BUNCHES_LS_B2',\n",
       " u'LHC.BOFSU:BPM_CAL_RDA_ERRORS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_ERROR_RATE',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_HIGH_HS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_HIGH_LS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_LOW_HS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_LOW_LS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_MID_HS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_MID_LS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_QUAL_HS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_QUAL_LS',\n",
       " u'LHC.BOFSU:BPM_HOR_CAL_SPREAD',\n",
       " u'LHC.BOFSU:BPM_HOR_INDEXES_OAF',\n",
       " u'LHC.BOFSU:BPM_MASK_H',\n",
       " u'LHC.BOFSU:BPM_MASK_V',\n",
       " u'LHC.BOFSU:BPM_NAMES_H',\n",
       " u'LHC.BOFSU:BPM_NAMES_V',\n",
       " u'LHC.BOFSU:BPM_STATUS_H',\n",
       " u'LHC.BOFSU:BPM_STATUS_V',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_ERROR_RATE',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_HIGH_HS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_HIGH_LS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_LOW_HS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_LOW_LS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_MID_HS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_MID_LS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_QUAL_HS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_QUAL_LS',\n",
       " u'LHC.BOFSU:BPM_VER_CAL_SPREAD',\n",
       " u'LHC.BOFSU:BPM_VER_INDEXES_OAF',\n",
       " u'LHC.BOFSU:NB_BPM_H',\n",
       " u'LHC.BOFSU:NB_BPM_V',\n",
       " u'LHC.BOFSU:REF_BPM_MASK_H',\n",
       " u'LHC.BOFSU:REF_BPM_MASK_V']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pytimber.LoggingDB()\n",
    "db.search('%BOFSU%BPM%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHC.BOFSU:BPM_NAMES_H\n",
      "2015-12-01 00:00:00.000 2015-12-15 00:00:00.000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No matching overloads found. at native/common/jp_method.cpp:121",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-dd54820f89e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2015-12-01 00:00:00.000'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2015-12-15 00:00:00.000'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgetsizeest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LHC.BOFSU:BPM_NAMES_H'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-ee74e708fe6c>\u001b[0m in \u001b[0;36mgetsizeest\u001b[1;34m(db, varlist, t1, t2)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mts2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetJVMHeapSizeEstimationForDataInTimeWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No matching overloads found. at native/common/jp_method.cpp:121"
     ]
    }
   ],
   "source": [
    "t1 = '2015-12-01 00:00:00.000'\n",
    "t2 = '2015-12-15 00:00:00.000'\n",
    "getsizeest(db,'LHC.BOFSU:BPM_NAMES_H',t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No matching overloads found. at native/common/jp_method.cpp:121",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-45be9de14764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetJVMHeapSizeEstimationForDataInTimeWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LHC.BOFSU:BPM_MASK_H'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: No matching overloads found. at native/common/jp_method.cpp:121"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import jpype\n",
    "db._ts.getJVMHeapSizeEstimationForDataInTimeWindow('LHC.BOFSU:BPM_MASK_H',t1,t2,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `LHCclass.py`:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "from matplotlib import pyplot as plt\n",
      "import csv\n",
      "import glob\n",
      "import datetime\n",
      "import collections\n",
      "import time\n",
      "import subprocess\n",
      "import os\n",
      "from scipy import optimize as opt\n",
      "from scipy import constants as const\n",
      "from StringIO import StringIO\n",
      "from matplotlib import rc,rcParams\n",
      "from matplotlib.patches import Rectangle\n",
      "import itertools\n",
      "\n",
      "# simdata\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "from pandas.tools.plotting import lag_plot\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "\n",
      "class LHCfill(object):\n",
      "    # names of timberdata we want to extract\n",
      "    timbervarFBCTB1    = 'LHC.BCTFR.A6R4.B1:BUNCH_INTENSITY'\n",
      "    timbervarFBCTB2    = 'LHC.BCTFR.A6R4.B2:BUNCH_INTENSITY'\n",
      "\n",
      "    timbervarBQMB1L    = 'LHC.BQM.B1:BUNCH_LENGTHS'\n",
      "    timbervarBQMB1F    = 'LHC.BQM.B1:FILLED_BUCKETS'\n",
      "\n",
      "    timbervarBQMB2L    = 'LHC.BQM.B2:BUNCH_LENGTHS'\n",
      "    timbervarBQMB2F    = 'LHC.BQM.B2:FILLED_BUCKETS'\n",
      "\n",
      "    timbervarBSRTB1H   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_H'\n",
      "    timbervarBSRTB1V   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_V'\n",
      "    timbervarBSRTB1GD  = 'LHC.BSRT.5R4.B1:GATE_DELAY'\n",
      "    timbervarBSRTB1CH  = 'LHC.BSRT.5R4.B1:LSF_H'\n",
      "    timbervarBSRTB1CV  = 'LHC.BSRT.5R4.B1:LSF_V'\n",
      "\n",
      "    timbervarBSRTB2H   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_H'\n",
      "    timbervarBSRTB2V   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_V'\n",
      "    timbervarBSRTB2GD  = 'LHC.BSRT.5L4.B2:GATE_DELAY'\n",
      "    timbervarBSRTB2CH  = 'LHC.BSRT.5L4.B2:LSF_H'\n",
      "    timbervarBSRTB2CV  = 'LHC.BSRT.5L4.B2:LSF_V'\n",
      "\n",
      "    timbervarLumiAtlas = \"ATLAS:LUMI_TOT_INST\"\n",
      "    timbervarLumiAlice = \"ALICE:LUMI_TOT_INST\"\n",
      "    timbervarLumiCMS   = \"CMS:LUMI_TOT_INST\"\n",
      "    timbervarLumiLHCB  = \"LHCB:LUMI_TOT_INST\"\n",
      "    \n",
      "    timbervarhorbpm    = 'LHC.BOFSU:POSITIONS_H'\n",
      "\n",
      "    # constants\n",
      "    protonmass = const.physical_constants['proton mass energy equivalent in MeV'][0]/1000 # GeV\n",
      "    ionA       = 208.\n",
      "    ionZ       = 82.\n",
      "    energy     = 6370\n",
      "    gamma      = energy * ionZ / 193.7291748489224\n",
      "\n",
      "    # beta's for the undulators and dipoles for the bsrt light\n",
      "    betaUndH = [203.,200.]\n",
      "    betaUndV = [318.,327.]\n",
      "    betaDipH = [214., 205.]\n",
      "    betaDipV = [328.,344.]\n",
      "    \n",
      "    #--------------------------------------------------------------------------------------------------\n",
      "    # initialization :\n",
      "    # ----------------\n",
      "    # fillnumber                : int\n",
      "    # basedir                   : string\n",
      "    # summarydf                 : pandas dataframe\n",
      "    # bunchlenb1df,bunchlenb1df : pandas dataframe\n",
      "    # ex1df,ey1df,ex2df,ey2df   : pandas dataframe\n",
      "    # I1df, I2df                : pandas dataframe\n",
      "    # lumiatlasdf,lumicmsdf,lumialicedf,lumilhcbdf : pandas dataframe\n",
      "    # bpmhdf                    : pandas dataframe\n",
      "    # bpmhmask                  : pandas dataframe\n",
      "    #--------------------------------------------------------------------------------------------------\n",
      "    def __init__(self,fillnumber,basedir):\n",
      "        self.fillnumber = fillnumber\n",
      "        self.basedir    = basedir\n",
      "        \n",
      "        self.summarydf, self.summaryfile     = self.getsummary()\n",
      "        self.bunchlenb1df, self.bunch2enb1df = self.getbunchlenghts('Fill' + str(self.fillnumber) + 'BLb1',\n",
      "                                                                    'Fill' + str(self.fillnumber) + 'BLb2')\n",
      "        \n",
      "        self.ex1df,self.ey1df,self.ex2df,self.ey2df = self.getemitbsrt('Fill' + str(self.fillnumber) +'emit1',\n",
      "                                                                       'Fill' + str(self.fillnumber)+'emit2') \n",
      "        \n",
      "        self.I1df,self.I2df                         = self.getFBCT('Fill' + str(self.fillnumber) +'fbct1',\n",
      "                                                                   'Fill' + str(self.fillnumber)+'fbct2')\n",
      "        \n",
      "        self.lumiatlasdf,self.lumicmsdf,self.lumialicedf,self.lumilhcbdf = self.getlumi('Fill' + \n",
      "                                                                                        str(self.fillnumber) +\n",
      "                                                                                        'atlas','Fill' + \n",
      "                                                                                        str(self.fillnumber)+\n",
      "                                                                                        'cms',\n",
      "                                                                                        'Fill' + \n",
      "                                                                                        str(self.fillnumber) +\n",
      "                                                                                        'alice','Fill' +\n",
      "                                                                                        str(self.fillnumber)+\n",
      "                                                                                        'lhcb')\n",
      "        self.bpmhdf    = self.gethorbpm('Fill' + str(self.fillnumber) +'bpmH')\n",
      "        self.bpmhmask  = self.gethorbpmmask('bpmhmask' + str(self.fillnumber))\n",
      "    \n",
      "    # returns fill summary\n",
      "    def getsummary(self):\n",
      "        infn   = \"Fill\" + str(self.fillnumber) + \"Summary\"\n",
      "        outfn  = self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\"\n",
      "        bashcmd1 = \"./cern-mdb -M FD -fn \" + str(self.fillnumber) + \" -N  \" + infn + \" -F CSV\"\n",
      "        bashcmd2 = \"mv \" + infn + \".CSV \" + outfn\n",
      "        subprocess.call(bashcmd1,shell=True)\n",
      "        subprocess.call(bashcmd2,shell=True)\n",
      "        dfsummary = pd.read_csv(outfn,delimiter=',',header=0)\n",
      "        return dfsummary, outfn+\".CSV\"\n",
      "    \n",
      "    # def convert to unix time\n",
      "    def converttimetounix(self,t):\n",
      "        return time.mktime(datetime.datetime.strptime(t,\"%Y-%m-%d %H:%M:%S.%f\").timetuple())\n",
      "    \n",
      "    # function for adding times in YY-mm-dd HH:MM:SS.fff format\n",
      "    def addtime(self,intime,deltahour):\n",
      "        mytime = datetime.datetime.strptime(intime,\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "        mytime += datetime.timedelta(hours=deltahour)\n",
      "        return mytime.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "    \n",
      "    # returns dict with start stop times of modes in a fill\n",
      "    def gettimes(self):\n",
      "        timesodic = collections.OrderedDict()\n",
      "        if os.path.isfile(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\"):\n",
      "            startdf = pd.read_csv(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\",\n",
      "                                  delimiter=',',header=0)\n",
      "            dc = collections.OrderedDict()\n",
      "            for name, group in startdf.groupby('Value'):\n",
      "                starttimes = group['StartTime(UTC_TIME)'].values\n",
      "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
      "                arr = np.array([starttimes,stoptimes])\n",
      "                dc[name] = np.transpose(arr)\n",
      "            return dc\n",
      "        else:\n",
      "            self.getsummary()\n",
      "            startdf = pd.read_csv(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\",\n",
      "                                  delimiter=',',header=0)\n",
      "            dc = collections.OrderedDict()\n",
      "            for name, group in startdf.groupby('Value'):\n",
      "                starttimes = group['StartTime(UTC_TIME)'].values\n",
      "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
      "                arr = np.array([starttimes,stoptimes])\n",
      "                dc[name] = np.transpose(arr)\n",
      "            return dc\n",
      "        \n",
      "    # returns arrays with the bunch slots\n",
      "    def getbunchpositions(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        \n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "            shcmdBQMFB1 = './cern-ldb -vs ' + self.timbervarBQMB1F + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            shcmdBQMFB2 = './cern-ldb -vs ' + self.timbervarBQMB2F + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "#             print shcmdBQMFB1\n",
      "            try:\n",
      "                subprocess.call(shcmdBQMFB1,shell=True)\n",
      "                subprocess.call(shcmdBQMFB2,shell=True)\n",
      "\n",
      "                bashcmd1 = \"mv \" + fnb1 + \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 + \".CSV \" + outfn2\n",
      "\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "\n",
      "                fileexist = True\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "                \n",
      "        if fileexist:\n",
      "            b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            return [int((i-1.)/10.) for i in b1bunchdata[range(1,3565)][b1bunchdata[range(1,3565)].sum(axis=1).values>0.1].tail(1).values[0] if i >0.1],                [int((i-1.)/10.) for i in b2bunchdata[range(1,3565)][b2bunchdata[range(1,3565)].sum(axis=1).values>0.1].tail(1).values[0] if i >0.1]\n",
      "        else:  \n",
      "            print 'Something went wrong, no data loaded.'\n",
      "    \n",
      "    # returns the bunch lengths \n",
      "    def getbunchlenghts(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "            shcmdBQMLB1 = './cern-ldb -vs ' + self.timbervarBQMB1L + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            shcmdBQMLB2 = './cern-ldb -vs ' + self.timbervarBQMB2L + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "#             print shcmdBQMFB1\n",
      "            try:\n",
      "                subprocess.call(shcmdBQMLB1,shell=True)\n",
      "                subprocess.call(shcmdBQMLB2,shell=True)\n",
      "\n",
      "                bashcmd1 = \"mv \" + fnb1 + \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 + \".CSV \" + outfn2\n",
      "\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "\n",
      "                fileexist = True\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "                \n",
      "        if fileexist:\n",
      "            b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            bposb1, bposb2 = self.getbunchpositions(fnb1+'pos',fnb2+'pos')\n",
      "            bposb1[:0]=[0]\n",
      "            bposb2[:0]=[0]\n",
      "            return b1bunchdata[bposb1],b2bunchdata[bposb2]\n",
      "        else:  \n",
      "            print 'Something went wrong, no data loaded.'\n",
      "            \n",
      "    def bsrtsigfromraw(self,bsrtgdreader,bsrtsighreader,bsrtsigvreader,bsrtzerotime):\n",
      "        exdict = collections.OrderedDict()\n",
      "        eydict = collections.OrderedDict()\n",
      "        \n",
      "        \n",
      "        # get end of ramp for switching betas\n",
      "        tdc = self.gettimes()\n",
      "        rampend = tdc['RAMP'][-1][-1]\n",
      "        rampend = self.converttimetounix(rampend)\n",
      "\n",
      "        for lhs,rhs,rrhs in itertools.izip(bsrtgdreader,bsrtsighreader,bsrtsigvreader):\n",
      "                # skip over the headers\n",
      "                if len(lhs) > 4:\n",
      "                    # since the BSRT light is either generated at the undulator or the dipole,\n",
      "                    # we have to select which beta is used \n",
      "                    if (int(lhs[0]) <= rampend):\n",
      "                        beta = self.betaUndH[0]\n",
      "                    else:\n",
      "                        beta = self.betaDipH[0]\n",
      "                    # looping through the columns of a row in the csv files\n",
      "                    for i in range(1,len(lhs)):\n",
      "                        # check if the key is already present in the output dictionary\n",
      "                        if int(float(lhs[i])) in exdict.keys():\n",
      "                            excomputed = self.gamma * float(rhs[i])**2/beta\n",
      "                            exdict[int(float(lhs[i]))].append([(int(lhs[0])-bsrtzerotime)/3600000.,excomputed])\n",
      "                        else:\n",
      "                            excomputed = self.gamma * float(rhs[i])**2/beta\n",
      "                            exdict[int(float(lhs[i]))]=[[(int(lhs[0])-bsrtzerotime)/3600000.,excomputed]]\n",
      "                        if int(float(lhs[i])) in eydict.keys():\n",
      "                            eycomputed = self.gamma * float(rrhs[i])**2/beta\n",
      "                            eydict[int(float(lhs[i]))].append([(int(lhs[0])-bsrtzerotime)/3600000.,eycomputed])\n",
      "                        else:\n",
      "                            eycomputed = self.gamma * float(rrhs[i])**2/beta\n",
      "                            eydict[int(float(lhs[i]))]=[[(int(lhs[0])-bsrtzerotime)/3600000.,eycomputed]]\n",
      "        return exdict,eydict\n",
      "    \n",
      "    def convertdicttodf(self,dictin):\n",
      "        dflist        = [pd.DataFrame(np.array(dictin[i]),columns=[0,i]) for i in dictin.keys()]\n",
      "        dflistgrouped = [dflist[i].groupby(0,as_index=False).mean() for i in range(len(dflist))]\n",
      "        dffinal       = reduce(lambda left,right: pd.merge(left,right,on=0,how='outer'),dflistgrouped)\n",
      "        dffinal2      = dffinal.fillna(0)\n",
      "        cols          = dffinal.columns\n",
      "        return dffinal2.loc[(dffinal2[cols[1:]]!=0).any(1)]\n",
      "    \n",
      "    def getemitbsrt(self,fnb1,fnb2):\n",
      "        if (os.path.isfile(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')):\n",
      "            ex1dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')\n",
      "            ey1dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY1.CSV')\n",
      "            ex2dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX2.CSV')\n",
      "            ey2dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY2.CSV')\n",
      "            return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
      "        else:\n",
      "            tdc = self.gettimes()\n",
      "            fileexist = False\n",
      "            outfn1  = self.basedir + \"/\" + fnb1 + 'sigh' + \".CSV\"\n",
      "            outfn2  = self.basedir + \"/\" + fnb1 + 'sigv' + \".CSV\"\n",
      "            outfn3  = self.basedir + \"/\" + fnb1 + 'gdh' + \".CSV\"\n",
      "            outfn4  = self.basedir + \"/\" + fnb1 + 'corh' + \".CSV\"\n",
      "            outfn5  = self.basedir + \"/\" + fnb1 + 'corv' + \".CSV\"\n",
      "            outfn6  = self.basedir + \"/\" + fnb2 + 'sigh' + \".CSV\"\n",
      "            outfn7  = self.basedir + \"/\" + fnb2 + 'sigv' + \".CSV\"\n",
      "            outfn8  = self.basedir + \"/\" + fnb2 + 'gdh' + \".CSV\"\n",
      "            outfn9  = self.basedir + \"/\" + fnb2 + 'corh' + \".CSV\"\n",
      "            outfn10  = self.basedir + \"/\" + fnb2 + 'corv' + \".CSV\"\n",
      "            if (os.path.isfile(self.basedir + '/' + fnb1 + 'sigh' + '.CSV')) and                    (os.path.isfile(self.basedir + '/' + fnb2  + 'sigh' + '.CSV')):\n",
      "                fileexist = True\n",
      "            else:\n",
      "                stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "                start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "                bashcmdBSRTSIGHB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1H + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'sigh' + ' -F CSV'\n",
      "                bashcmdBSRTSIGVB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1V + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'sigv' + ' -F CSV'\n",
      "                bashcmdBSRTGDHB1  = './cern-ldb -vs ' +  self.timbervarBSRTB1GD + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'gdh' + ' -F CSV'\n",
      "                bashcmdBSRTCORHB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1CH + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'corh' + ' -F CSV'\n",
      "                bashcmdBSRTCORVB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1CV + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'corv' + ' -F CSV'\n",
      "\n",
      "                bashcmdBSRTSIGHB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2H + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'sigh' + ' -F CSV'\n",
      "                bashcmdBSRTSIGVB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2V + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'sigv' + ' -F CSV'\n",
      "                bashcmdBSRTGDHB2  = './cern-ldb -vs ' +  self.timbervarBSRTB2GD + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'gdh' + ' -F CSV'\n",
      "                bashcmdBSRTCORHB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2CH + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'corh' + ' -F CSV'\n",
      "                bashcmdBSRTCORVB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2CV + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'corv' + ' -F CSV'\n",
      "\n",
      "                try:\n",
      "                    subprocess.call(bashcmdBSRTSIGHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTSIGVB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTGDHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORVB1,shell=True)\n",
      "\n",
      "                    subprocess.call(bashcmdBSRTSIGHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTSIGVB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTGDHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORVB2,shell=True)\n",
      "\n",
      "                    bashcmd1 = \"mv \" + fnb1 + 'sigh' + \".CSV \" + outfn1\n",
      "                    bashcmd2 = \"mv \" + fnb1 + 'sigv' + \".CSV \" + outfn2\n",
      "                    bashcmd3 = \"mv \" + fnb1 + 'gdh'  + \".CSV \" + outfn3\n",
      "                    bashcmd4 = \"mv \" + fnb1 + 'corh' + \".CSV \" + outfn4\n",
      "                    bashcmd5 = \"mv \" + fnb1 + 'corv' + \".CSV \" + outfn5\n",
      "\n",
      "                    bashcmd6 = \"mv \" + fnb2 + 'sigh' + \".CSV \" + outfn6\n",
      "                    bashcmd7 = \"mv \" + fnb2 + 'sigv' + \".CSV \" + outfn7\n",
      "                    bashcmd8 = \"mv \" + fnb2 + 'gdh'  + \".CSV \" + outfn8\n",
      "                    bashcmd9 = \"mv \" + fnb2 + 'corh' + \".CSV \" + outfn9\n",
      "                    bashcmd10 = \"mv \" + fnb2 + 'corv' + \".CSV \" + outfn10\n",
      "\n",
      "                    subprocess.call(bashcmd1,shell=True)\n",
      "                    subprocess.call(bashcmd2,shell=True)\n",
      "                    subprocess.call(bashcmd3,shell=True)\n",
      "                    subprocess.call(bashcmd4,shell=True)\n",
      "                    subprocess.call(bashcmd5,shell=True)\n",
      "                    subprocess.call(bashcmd6,shell=True)\n",
      "                    subprocess.call(bashcmd7,shell=True)\n",
      "                    subprocess.call(bashcmd8,shell=True)\n",
      "                    subprocess.call(bashcmd9,shell=True)\n",
      "                    subprocess.call(bashcmd10,shell=True)\n",
      "\n",
      "                    fileexist = True\n",
      "                except:\n",
      "                    print 'Loading of data failed.'\n",
      "            if fileexist:\n",
      "                # opening the files\n",
      "                fgdb1   = open(outfn3,'rU')\n",
      "                fsighb1 = open(outfn1,'rU')\n",
      "                fsigvb1 = open(outfn2,'rU')\n",
      "\n",
      "                fgdb2   = open(outfn8,'rU')\n",
      "                fsighb2 = open(outfn6,'rU')\n",
      "                fsigvb2 = open(outfn7,'rU')\n",
      "\n",
      "                # creating the csv_reader objects\n",
      "                bsrtgdb1reader = csv.reader(fgdb1)\n",
      "                bsrtsighb1reader = csv.reader(fsighb1)\n",
      "                bsrtsigvb1reader = csv.reader(fsigvb1)\n",
      "\n",
      "                bsrtgdb2reader = csv.reader(fgdb2)\n",
      "                bsrtsighb2reader = csv.reader(fsighb2)\n",
      "                bsrtsigvb2reader = csv.reader(fsigvb2)\n",
      "\n",
      "                # creating a variable containing the zero time moment\n",
      "                rowlist      = [row for row in bsrtgdb1reader]\n",
      "                bsrtzerotime = int(rowlist[3][0])\n",
      "\n",
      "                rowlistb2      = [row for row in bsrtgdb2reader]\n",
      "                bsrtzerotimeb2 = int(rowlistb2[3][0])\n",
      "\n",
      "                # reloading the GD file and recreating the csv_reader object since it has been used (Pointers!!!)\n",
      "                fgdb1 =open(outfn3,'rU')\n",
      "                bsrtgdb1reader = csv.reader(fgdb1)\n",
      "\n",
      "                fgdb2 =open(outfn8,'rU')\n",
      "                bsrtgdb2reader = csv.reader(fgdb2)\n",
      "\n",
      "                # initializing the dictionary that will contain the processed data\n",
      "                # keys are the bunchslot numbers\n",
      "                # values are a list of 2D lists that contain a timestamp and the normalized emittance at that time\n",
      "                exb1dict = collections.OrderedDict()\n",
      "                eyb1dict = collections.OrderedDict()\n",
      "                exb2dict = collections.OrderedDict()\n",
      "                eyb2dict = collections.OrderedDict()\n",
      "\n",
      "                exb1dict,eyb1dict = self.bsrtsigfromraw(bsrtgdb1reader,bsrtsighb1reader,bsrtsigvb1reader,bsrtzerotime)\n",
      "                exb2dict,eyb2dict = self.bsrtsigfromraw(bsrtgdb2reader,bsrtsighb2reader,bsrtsigvb2reader,bsrtzerotimeb2)\n",
      "\n",
      "                bashcmd1 = \"rm \" + outfn1\n",
      "                bashcmd2 = \"rm \" + outfn2\n",
      "                bashcmd3 = \"rm \" + outfn3\n",
      "                bashcmd4 = \"rm \" + outfn4\n",
      "                bashcmd5 = \"rm \" + outfn5\n",
      "\n",
      "                bashcmd6 = \"rm \" + outfn6\n",
      "                bashcmd7 = \"rm \" + outfn7\n",
      "                bashcmd8 = \"rm \" + outfn8\n",
      "                bashcmd9 = \"rm \" + outfn9\n",
      "                bashcmd10 = \"rm \" + outfn10\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                subprocess.call(bashcmd3,shell=True)\n",
      "                subprocess.call(bashcmd4,shell=True)\n",
      "                subprocess.call(bashcmd5,shell=True)\n",
      "                subprocess.call(bashcmd6,shell=True)\n",
      "                subprocess.call(bashcmd7,shell=True)\n",
      "                subprocess.call(bashcmd8,shell=True)\n",
      "                subprocess.call(bashcmd9,shell=True)\n",
      "                subprocess.call(bashcmd10,shell=True)\n",
      "                \n",
      "                ex1dfout =self.convertdicttodf(exb1dict)\n",
      "                ey1dfout =self.convertdicttodf(eyb1dict)\n",
      "                ex2dfout =self.convertdicttodf(exb2dict)\n",
      "                ey2dfout =self.convertdicttodf(eyb2dict)\n",
      "        \n",
      "                ex1dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')\n",
      "                ey1dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY1.CSV')\n",
      "                ex2dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX2.CSV')\n",
      "                ey2dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY2.CSV')\n",
      "                \n",
      "                return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
      "            else:\n",
      "                print 'Something went wrong, no data loaded'\n",
      "                \n",
      "    def getFBCT(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        \n",
      "        cols1,cols2 = self.getbunchpositions(fnb1+'pos',fnb2+'pos')\n",
      "        cols1 = [i + 1 for i in cols1]\n",
      "        cols2 = [i + 1 for i in cols2]\n",
      "        cols1[:0] = [0]\n",
      "        cols2[:0] = [0]\n",
      "        \n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            \n",
      "            bashcmdFBCTB1 = './cern-ldb -vs ' +  self.timbervarFBCTB1 + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            bashcmdFBCTB2 = './cern-ldb -vs ' +  self.timbervarFBCTB2 + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdFBCTB1,shell=True)\n",
      "                subprocess.call(bashcmdFBCTB2,shell=True)\n",
      "                \n",
      "                bashcmd1 = \"mv \" + fnb1 +  \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 +  \".CSV \" + outfn2\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                fileexist = True\n",
      "            \n",
      "                b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,names=range(3565),\n",
      "                                          skiprows=[0,1,2],usecols=cols1)\n",
      "                b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,names=range(3565),\n",
      "                                          skiprows=[0,1,2],usecols=cols2)\n",
      "                b1bunchdata.columns = [i-1 if i !=0 else 0 for i in cols1]\n",
      "                b2bunchdata.columns = [i-1 if i !=0 else 0 for i in cols2]\n",
      "                b1bunchdata.to_csv(outfn1,index=None)\n",
      "                b2bunchdata.to_csv(outfn2,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            \n",
      "            b1bunchdata = pd.read_csv(outfn1)\n",
      "            b2bunchdata = pd.read_csv(outfn2)\n",
      "            return b1bunchdata,b2bunchdata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "    \n",
      "    def getlumi(self,fnatlas,fncms,fnalice,fnlhcb):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfnatlas  = self.basedir + \"/\" + fnatlas + \".CSV\"\n",
      "        outfncms    = self.basedir + \"/\" + fncms   + \".CSV\"\n",
      "        outfnalice  = self.basedir + \"/\" + fnalice + \".CSV\"\n",
      "        outfnlhcb   = self.basedir + \"/\" + fnlhcb  + \".CSV\"        \n",
      "        \n",
      "        if os.path.isfile(self.basedir + '/' + fnatlas + '.CSV'):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            \n",
      "            bashcmdatlas = './cern-ldb -vs ' +  self.timbervarLumiAtlas + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnatlas + ' -F CSV'\n",
      "            bashcmdcms   = './cern-ldb -vs ' +  self.timbervarLumiCMS + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fncms + ' -F CSV'\n",
      "            bashcmdalice = './cern-ldb -vs ' +  self.timbervarLumiAlice + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnalice + ' -F CSV'\n",
      "            bashcmdlhcb  = './cern-ldb -vs ' +  self.timbervarLumiLHCB + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnlhcb + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdatlas,shell=True)\n",
      "                subprocess.call(bashcmdcms,shell=True)\n",
      "                subprocess.call(bashcmdalice,shell=True)\n",
      "                subprocess.call(bashcmdlhcb,shell=True)\n",
      "                \n",
      "                bashcmd1 = \"mv \" + fnatlas +  \".CSV \" + outfnatlas\n",
      "                bashcmd2 = \"mv \" + fncms   +  \".CSV \" + outfncms\n",
      "                bashcmd3 = \"mv \" + fnalice +  \".CSV \" + outfnalice\n",
      "                bashcmd4 = \"mv \" + fnlhcb  +  \".CSV \" + outfnlhcb\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                subprocess.call(bashcmd3,shell=True)\n",
      "                subprocess.call(bashcmd4,shell=True)\n",
      "                \n",
      "                fileexist = True\n",
      "            \n",
      "                atlaslumidata = pd.read_csv(outfnatlas,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                cmslumidata = pd.read_csv(outfncms,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                alicelumidata = pd.read_csv(outfnalice,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                lhcblumidata = pd.read_csv(outfnlhcb,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                \n",
      "                atlaslumidata.to_csv(outfnatlas,index=None)\n",
      "                cmslumidata.to_csv(outfncms,index=None)\n",
      "                alicelumidata.to_csv(outfnalice,index=None)\n",
      "                lhcblumidata.to_csv(outfnlhcb,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            \n",
      "            atlaslumidata = pd.read_csv(outfnatlas)\n",
      "            cmslumidata = pd.read_csv(outfncms)\n",
      "            alicelumidata = pd.read_csv(outfnalice)\n",
      "            lhcblumidata = pd.read_csv(outfnlhcb)\n",
      "            return atlaslumidata,cmslumidata,alicelumidata,lhcblumidata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "    \n",
      "    def gethorbpm(self,fn):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
      "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            bashcmdhorbpm = './cern-ldb -vs ' +  self.timbervarhorbpm + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -sa REPEAT -ss 5 -si MINUTE -N ' + fn + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdhorbpm,shell=True)\n",
      "                fileexist = True\n",
      "                bashcmd1 = \"mv \" + fn +  \".CSV \" + outfn\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                \n",
      "                bpmdata = pd.read_csv(outfn,delimiter=',',header=None,\n",
      "                                          skiprows=[0,1,2])\n",
      "                bpmdata.to_csv(outfn,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
      "            colnames = list(df.columns[1:])\n",
      "            colnames[:0] =['t']\n",
      "            bpmdata = pd.read_csv(outfn,names=colnames,skiprows=[0])\n",
      "            return bpmdata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "        \n",
      "    def gethorbpmmask(self,fn):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
      "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_MASK_H' + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"'  + stop + '\\\" -N ' + 'bpmhmask' + str(self.fillnumber) + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdhorbpmnames,shell=True)\n",
      "                fileexist = True\n",
      "                bashcmd1 = \"mv \" + 'bpmhmask4696' +  \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhmask4696.csv'\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                dfmask = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
      "                dfmask.to_csv(outfn,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            df = pd.read_csv(outfn,skiprows=[0,1,2])\n",
      "            bpmdata = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
      "            return bpmdata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "        \n",
      "    def getbpmhreduced(self):\n",
      "        dfmask = self.bpmhmask\n",
      "\n",
      "        # selecting the last non-zero row of the maskfile to use as a mask on the bpm data\n",
      "        # not the best way but does the job for the moment\n",
      "        # problem to unequal shape of mask and data dataframes\n",
      "        dfcopy = pd.DataFrame(dfmask[range(1,1089)][dfmask[range(1,1089)].sum(axis=1).values>1.].tail(1).values, \n",
      "                              columns =  self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1).columns)\n",
      "\n",
      "        # taking the bpm data but removing the timestamps in order to be able to apply a mask\n",
      "        dffff = self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1)\n",
      "        selection = dffff * dfcopy.iloc[0]\n",
      "        selectionred= selection[(selection>1.0)| (selection< -1.0)].dropna(axis=1,how='all')\n",
      "        return selectionred\n",
      "    \n",
      "    def transformbpmdata(self,tfslhcb1,tfslhcb2,ipnr=5):\n",
      "        selectionred = self.getbpmhreduced()\n",
      "        # selecting the BPM around the desired ip (pandas dataframes)\n",
      "        bpmrtest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R' + str(ipnr)\n",
      "                                                                                                   + '.B1')])]\n",
      "        bpmltest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L' + str(ipnr)\n",
      "                                                                                                   + '.B2')])]\n",
      "        # adding the s positions of these BPMs for plotting\n",
      "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
      "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
      "        colsb1 = list(tfsb1.columns[1:])\n",
      "\n",
      "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
      "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
      "\n",
      "        tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R' + str(ipnr) + '.B1'))]\n",
      "        tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
      "        tfsbpmr = tfsbpmr[['NAME','S']]\n",
      "\n",
      "        namesr = list(bpmrtest.columns)\n",
      "\n",
      "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
      "        tfsb2 = tfsb2[tfsb2['NAME']!='%s']\n",
      "        colsb2 = list(tfsb2.columns[1:])\n",
      "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
      "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
      "        tfsbpml = tfsb2[(tfsb2['NAME'].str.contains('BPM')) & (tfsb2['NAME'].str.contains('L' + str(ipnr) + '.B2'))]\n",
      "        tfsbpml = tfsbpml[1:]\n",
      "        tfsbpml = tfsbpml[['NAME','S']]\n",
      "\n",
      "        namesl = list(bpmltest.columns)\n",
      "\n",
      "        return bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr\n",
      "    \n",
      "    def plotbpm(self,tfslhcb1,tfslhcb2,ipnr=5,nn=50,step=20,xmin=0,xmax=600):\n",
      "        bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr = self.transformbpmdata(\n",
      "                                                    tfslhcb1,\n",
      "                                                    tfslhcb2,\n",
      "                                                    ipnr=ipnr\n",
      "                                                   )\n",
      "        from IPython.html.widgets import FloatProgress\n",
      "        from IPython.display import display\n",
      "        f = FloatProgress(min=0,max=2*nn/float(step))\n",
      "        display(f)\n",
      "\n",
      "        error = False\n",
      "\n",
      "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
      "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
      "        colsb1 = list(tfsb1.columns[1:])\n",
      "\n",
      "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
      "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
      "        sipb1 = tfsb1[tfsb1['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
      "\n",
      "        tfsb2  = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
      "        tfsb2  = tfsb2[tfsb2['NAME']!='%s']\n",
      "        colsb2 = list(tfsb2.columns[1:])\n",
      "\n",
      "        tfsb2 = pd.read_csv(tfslhcb2, skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
      "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
      "        sipb2 = tfsb2[tfsb2['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
      "\n",
      "        tfsbpmr['S'] = tfsbpmr['S'].apply(lambda x: float(x)-float(sipb1))\n",
      "        tfsbpml['S'] = tfsbpml['S'].apply(lambda x: float(x)-float(sipb2))\n",
      "\n",
      "    #     print tfsbpmr\n",
      "\n",
      "        fig = plt.figure(figsize=(18,20))\n",
      "        ax  = fig.add_subplot(211)\n",
      "\n",
      "        s1   = np.array([float(tfsbpml[tfsbpml['NAME']==n]['S'].values[0]) for n in namesl])\n",
      "        max1 = len(bpmltest)\n",
      "\n",
      "\n",
      "        for i in range(0,len(bpmltest.tail(nn)),step):\n",
      "            try:\n",
      "                data = np.array([bpmltest[n][max1-nn+i] for n in namesl])\n",
      "                plt.scatter(s1,data)\n",
      "                plt.plot(s1,data)\n",
      "                f.value = i\n",
      "            except:\n",
      "                print 'nn out of range'\n",
      "                error = True\n",
      "                break\n",
      "\n",
      "\n",
      "    #     plt.plot((0,500),(500,500),'k-')\n",
      "    #     plt.plot((0,500),(-500,-500),'k-')\n",
      "    #     plt.plot((0,500),(-3000,-3000),'k-')\n",
      "    #     plt.plot((0,500),(-3500,-3500),'k-')\n",
      "    #     plt.plot((0,500),(0,0),'k-')\n",
      "        plt.grid()\n",
      "        plt.xlim(xmin,xmax)\n",
      "        plt.ylim(-5000,5000)\n",
      "\n",
      "        ax.set_xticks(np.arange(xmin,xmax,100))\n",
      "        ax.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
      "        ax.set_yticks(np.arange(-5000,5000,2000))\n",
      "        ax.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
      "        ax.grid(which='minor',alpha=0.65)\n",
      "\n",
      "        plt.xlabel('s',fontsize=16.0)\n",
      "        plt.ylabel('x [um]')\n",
      "        plt.title('BPM orbits Horizontal left of ' + str(ipnr) + ' - fill ' + str(LHCfill.fillnumber))\n",
      "\n",
      "    #     ax.text(100,4000, 'Each line (colour) is at a different timestamp.')\n",
      "\n",
      "    #     ax.annotate('roughly 0.5 mm below \\n 3mm from bump',xy=(440,-3400),xytext=(400,-5000),\n",
      "    #                 arrowprops=dict(facecolor='red',shrink=0.5))\n",
      "\n",
      "    #     ax.plot([440],[500],'o')\n",
      "\n",
      "    #     ax.annotate('Expected with 0.5 mm bump',xy=(440,500),xytext=(400,2500),\n",
      "    #                 arrowprops=dict(facecolor='red',shrink=0.2))\n",
      "\n",
      "        ax2  = fig.add_subplot(2,1,2)\n",
      "        max2 = len(bpmrtest)\n",
      "        s2   = np.array([float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]) for n in namesr])\n",
      "\n",
      "        for i in range(0,len(bpmrtest.tail(nn)),step):\n",
      "            try:\n",
      "                data =  np.array([bpmrtest[n][max2-nn+i] for n in namesr])\n",
      "                ax2.scatter(s2,data)\n",
      "                ax2.plot(s2,data)\n",
      "                f.value = f.value +1 \n",
      "            except:\n",
      "                print 'nn out of range'\n",
      "                error = True\n",
      "                break\n",
      "        if error:\n",
      "            print 'No valid plot generated'\n",
      "        else:\n",
      "    #         plt.plot((0,500),(500,500),'k-')\n",
      "    #         plt.plot((0,500),(-500,-500),'k-')\n",
      "    #         plt.plot((0,500),(-3000,-3000),'k-')\n",
      "    #         plt.plot((0,500),(-3500,-3500),'k-')\n",
      "    #         plt.plot((0,500),(0,0),'k-')\n",
      "            plt.grid()\n",
      "            plt.xlim(xmin,xmax)\n",
      "            plt.ylim(-5000,5000)\n",
      "\n",
      "            ax2.set_xticks(np.arange(xmin,xmax,100))\n",
      "            ax2.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
      "            ax2.set_yticks(np.arange(-5000,5000,2000))\n",
      "            ax2.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
      "\n",
      "            ax2.grid(which='minor',alpha=0.65)\n",
      "    #         ax2.annotate('roughly 0.5 mm above \\n 3mm from bump',xy=(433,-2650),xytext=(400,-5000),\n",
      "    #                     arrowprops=dict(facecolor='red',shrink=0.2))\n",
      "\n",
      "            plt.xlabel('s',fontsize=16.0)\n",
      "            plt.ylabel('x [um]')\n",
      "            plt.title('BPM orbits Horizontal right of ' + str(ipnr) + '  - fill ' + str(LHCfill.fillnumber) )\n",
      "\n",
      "            plt.show()\n",
      "            print f.value\n",
      "            # plt.savefig('Fill4707IP5bpm.png',format='png')\n"
     ]
    }
   ],
   "source": [
    "%save -f LHCclass.py 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the names of the BPM's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>BPMSW.1R1.B1</th>\n",
       "      <th>BPMWF.A1R1.B1</th>\n",
       "      <th>BPMS.2R1.B1</th>\n",
       "      <th>BPMSY.4R1.B1</th>\n",
       "      <th>BPMWB.4R1.B1</th>\n",
       "      <th>BPMYA.4R1.B1</th>\n",
       "      <th>BPM.5R1.B1</th>\n",
       "      <th>BPMR.6R1.B1</th>\n",
       "      <th>BPMSX.7R1.B1</th>\n",
       "      <th>...</th>\n",
       "      <th>BPM.7L1.B2</th>\n",
       "      <th>BPMSX.7L1.B2</th>\n",
       "      <th>BPMR.6L1.B2</th>\n",
       "      <th>BPM.5L1.B2</th>\n",
       "      <th>BPMYA.4L1.B2</th>\n",
       "      <th>BPMWB.4L1.B2</th>\n",
       "      <th>BPMSY.4L1.B2</th>\n",
       "      <th>BPMS.2L1.B2</th>\n",
       "      <th>BPMWF.A1L1.B2</th>\n",
       "      <th>BPMSW.1L1.B2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1449397723485</td>\n",
       "      <td>BPMSW.1R1.B1</td>\n",
       "      <td>BPMWF.A1R1.B1</td>\n",
       "      <td>BPMS.2R1.B1</td>\n",
       "      <td>BPMSY.4R1.B1</td>\n",
       "      <td>BPMWB.4R1.B1</td>\n",
       "      <td>BPMYA.4R1.B1</td>\n",
       "      <td>BPM.5R1.B1</td>\n",
       "      <td>BPMR.6R1.B1</td>\n",
       "      <td>BPMSX.7R1.B1</td>\n",
       "      <td>...</td>\n",
       "      <td>BPM.7L1.B2</td>\n",
       "      <td>BPMSX.7L1.B2</td>\n",
       "      <td>BPMR.6L1.B2</td>\n",
       "      <td>BPM.5L1.B2</td>\n",
       "      <td>BPMYA.4L1.B2</td>\n",
       "      <td>BPMWB.4L1.B2</td>\n",
       "      <td>BPMSY.4L1.B2</td>\n",
       "      <td>BPMS.2L1.B2</td>\n",
       "      <td>BPMWF.A1L1.B2</td>\n",
       "      <td>BPMSW.1L1.B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               t  BPMSW.1R1.B1  BPMWF.A1R1.B1  BPMS.2R1.B1  BPMSY.4R1.B1  \\\n",
       "0  1449397723485  BPMSW.1R1.B1  BPMWF.A1R1.B1  BPMS.2R1.B1  BPMSY.4R1.B1   \n",
       "\n",
       "   BPMWB.4R1.B1  BPMYA.4R1.B1  BPM.5R1.B1  BPMR.6R1.B1  BPMSX.7R1.B1  \\\n",
       "0  BPMWB.4R1.B1  BPMYA.4R1.B1  BPM.5R1.B1  BPMR.6R1.B1  BPMSX.7R1.B1   \n",
       "\n",
       "       ...       BPM.7L1.B2  BPMSX.7L1.B2  BPMR.6L1.B2  BPM.5L1.B2  \\\n",
       "0      ...       BPM.7L1.B2  BPMSX.7L1.B2  BPMR.6L1.B2  BPM.5L1.B2   \n",
       "\n",
       "   BPMYA.4L1.B2  BPMWB.4L1.B2  BPMSY.4L1.B2  BPMS.2L1.B2  BPMWF.A1L1.B2  \\\n",
       "0  BPMYA.4L1.B2  BPMWB.4L1.B2  BPMSY.4L1.B2  BPMS.2L1.B2  BPMWF.A1L1.B2   \n",
       "\n",
       "   BPMSW.1L1.B2  \n",
       "0  BPMSW.1L1.B2  \n",
       "\n",
       "[1 rows x 1089 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_NAMES_H' + ' -t1 \\\"' + '2015-12-06 00:52:09.555' +\\\n",
    "#                             '\\\" -t2 \\\"' + '2015-12-06 12:39:41.084' + '\\\" -N ' + 'bpmnames' + ' -F CSV'\n",
    "# subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "# bashcmd1 = \"mv \" + 'bpmnames' +  \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv'\n",
    "# subprocess.call(bashcmd1,shell=True)\n",
    "df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
    "df.columns[1:]\n",
    "colnames = list(df.columns[1:])\n",
    "colnames[:0] =['t']\n",
    "print len(colnames)\n",
    "df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2],names=colnames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u't', u'BPMSW.1R1.B1', u'BPMWF.A1R1.B1', u'BPMS.2R1.B1',\n",
       "       u'BPMSY.4R1.B1', u'BPMWB.4R1.B1', u'BPMYA.4R1.B1', u'BPM.5R1.B1',\n",
       "       u'BPMR.6R1.B1', u'BPMSX.7R1.B1',\n",
       "       ...\n",
       "       u'BPM.7L1.B2', u'BPMSX.7L1.B2', u'BPMR.6L1.B2', u'BPM.5L1.B2',\n",
       "       u'BPMYA.4L1.B2', u'BPMWB.4L1.B2', u'BPMSY.4L1.B2', u'BPMS.2L1.B2',\n",
       "       u'BPMWF.A1L1.B2', u'BPMSW.1L1.B2'],\n",
       "      dtype='object', length=1089)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill =  LHCfill(4707,'/afs/cern.ch/work/t/tomerten/HI2015')\n",
    "fill4696 =  LHCfill(4696,'/afs/cern.ch/work/t/tomerten/HI2015')\n",
    "fill.summarydf\n",
    "fill.bpmdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globals()['rcParams']['font.size']=16.0\n",
    "globals()['rcParams']['xtick.major.size']=12.0\n",
    "globals()['rcParams']['ytick.major.size']=12.0\n",
    "globals()['rcParams']['axes.labelsize']=12.0\n",
    "globals()['rcParams']['xtick.labelsize']=12.0\n",
    "globals()['rcParams']['ytick.labelsize']=12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "      <th>StartTime(UTC_TIME)</th>\n",
       "      <th>EndTime(UTC_TIME)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fill Number</td>\n",
       "      <td>4696</td>\n",
       "      <td>2015-12-06 00:52:09.555</td>\n",
       "      <td>2015-12-06 12:39:41.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>SETUP</td>\n",
       "      <td>2015-12-06 01:17:10.386</td>\n",
       "      <td>2015-12-06 01:30:54.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>INJPROT</td>\n",
       "      <td>2015-12-06 01:30:54.124</td>\n",
       "      <td>2015-12-06 02:40:54.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>2015-12-06 02:40:54.557</td>\n",
       "      <td>2015-12-06 03:31:38.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>INJPROT</td>\n",
       "      <td>2015-12-06 03:31:38.953</td>\n",
       "      <td>2015-12-06 04:05:37.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>2015-12-06 04:05:37.838</td>\n",
       "      <td>2015-12-06 04:23:38.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>INJPHYS</td>\n",
       "      <td>2015-12-06 04:23:38.006</td>\n",
       "      <td>2015-12-06 06:01:41.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>PRERAMP</td>\n",
       "      <td>2015-12-06 06:01:41.019</td>\n",
       "      <td>2015-12-06 06:07:06.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>RAMP</td>\n",
       "      <td>2015-12-06 06:07:06.777</td>\n",
       "      <td>2015-12-06 06:27:34.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>FLATTOP</td>\n",
       "      <td>2015-12-06 06:27:34.727</td>\n",
       "      <td>2015-12-06 06:30:56.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>2015-12-06 06:30:56.851</td>\n",
       "      <td>2015-12-06 06:37:37.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>2015-12-06 06:37:37.319</td>\n",
       "      <td>2015-12-06 06:50:44.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>ADJUST</td>\n",
       "      <td>2015-12-06 06:50:44.838</td>\n",
       "      <td>2015-12-06 07:03:53.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>STABLE</td>\n",
       "      <td>2015-12-06 07:03:53.246</td>\n",
       "      <td>2015-12-06 12:32:37.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>BEAMDUMP</td>\n",
       "      <td>2015-12-06 12:32:37.209</td>\n",
       "      <td>2015-12-06 12:34:16.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Beam Mode</td>\n",
       "      <td>RAMPDOWN</td>\n",
       "      <td>2015-12-06 12:34:16.600</td>\n",
       "      <td>2015-12-06 12:39:41.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Description     Value      StartTime(UTC_TIME)        EndTime(UTC_TIME)\n",
       "0   Fill Number      4696  2015-12-06 00:52:09.555  2015-12-06 12:39:41.084\n",
       "1     Beam Mode     SETUP  2015-12-06 01:17:10.386  2015-12-06 01:30:54.123\n",
       "2     Beam Mode   INJPROT  2015-12-06 01:30:54.124  2015-12-06 02:40:54.556\n",
       "3     Beam Mode   INJPHYS  2015-12-06 02:40:54.557  2015-12-06 03:31:38.952\n",
       "4     Beam Mode   INJPROT  2015-12-06 03:31:38.953  2015-12-06 04:05:37.837\n",
       "5     Beam Mode   INJPHYS  2015-12-06 04:05:37.838  2015-12-06 04:23:38.005\n",
       "6     Beam Mode   INJPHYS  2015-12-06 04:23:38.006  2015-12-06 06:01:41.018\n",
       "7     Beam Mode   PRERAMP  2015-12-06 06:01:41.019  2015-12-06 06:07:06.776\n",
       "8     Beam Mode      RAMP  2015-12-06 06:07:06.777  2015-12-06 06:27:34.726\n",
       "9     Beam Mode   FLATTOP  2015-12-06 06:27:34.727  2015-12-06 06:30:56.850\n",
       "10    Beam Mode   SQUEEZE  2015-12-06 06:30:56.851  2015-12-06 06:37:37.318\n",
       "11    Beam Mode   SQUEEZE  2015-12-06 06:37:37.319  2015-12-06 06:50:44.837\n",
       "12    Beam Mode    ADJUST  2015-12-06 06:50:44.838  2015-12-06 07:03:53.245\n",
       "13    Beam Mode    STABLE  2015-12-06 07:03:53.246  2015-12-06 12:32:37.208\n",
       "14    Beam Mode  BEAMDUMP  2015-12-06 12:32:37.209  2015-12-06 12:34:16.599\n",
       "15    Beam Mode  RAMPDOWN  2015-12-06 12:34:16.600  2015-12-06 12:39:41.084"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the times for downloading the mask\n",
    "fill4696.summarydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masktest = fill.gethorbpmmask('bpmhmask4696')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading the mask\n",
    "bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_MASK_H' + ' -t1 \\\"' + '2015-12-06 00:52:09.555' +\\\n",
    "                            '\\\" -t2 \\\"' + '2015-12-06 12:39:41.084' + '\\\" -N ' + 'bpmmask4696' + ' -F CSV'\n",
    "subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "bashcmd1 = \"mv \" + 'bpmmask4696' +  \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhmask4696.csv'\n",
    "subprocess.call(bashcmd1,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "# ---------------------\n",
    "\n",
    "selectionred = fill4696.getbpmhreduced()\n",
    "# selecting bpm right and left of ip5\n",
    "bpmr5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R5.B1')])]\n",
    "bpml5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L5.B2')])]\n",
    "\n",
    "\n",
    "tfsb1 =pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfsb1 = tfsb1[tfsb1['NAME']!='%s']\n",
    "colsb1 = list(tfsb1.columns[1:])\n",
    "tfsb1 = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R5.B1'))]\n",
    "tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "namesr = list(bpmr5test.columns)\n",
    "\n",
    "# [[float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]),bpmr5test[n][0]] for n in namesr]\n",
    "# (fill4696.bpmdf['t'].tail(50)-fill4696.bpmdf['t'].head(1).values)/3600000\n",
    "bpmr5test.tail(50)\n",
    "\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfs = tfs[tfs['NAME']!='%s']\n",
    "cols = list(tfs.columns[1:])\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(46),delim_whitespace=True,names=cols,index_col=False)\n",
    "tfs = tfs[tfs['S']!='%s']\n",
    "tfsbpm= tfs[(tfs['NAME'].str.contains('BPM')) & (tfs['NAME'].str.contains('L5.B2'))]\n",
    "tfsbpm = tfsbpm[1:]\n",
    "tfsbpm = tfsbpm[['NAME','S']]\n",
    "names = list(bpml5test.columns)\n",
    "\n",
    "# bpml5test.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'BPM.32L5.B2', u'BPM.31L5.B2', u'BPM.30L5.B2', u'BPM.29L5.B2',\n",
      "       u'BPM.28L5.B2', u'BPM.27L5.B2', u'BPM.26L5.B2', u'BPM.25L5.B2',\n",
      "       u'BPM.24L5.B2', u'BPM.23L5.B2', u'BPM.22L5.B2', u'BPM.21L5.B2',\n",
      "       u'BPM.20L5.B2', u'BPM.19L5.B2', u'BPM.18L5.B2', u'BPM.17L5.B2',\n",
      "       u'BPM.16L5.B2', u'BPM.15L5.B2', u'BPM.14L5.B2', u'BPM.13L5.B2',\n",
      "       u'BPM.12L5.B2', u'BPM.11L5.B2', u'BPM.10L5.B2', u'BPM.9L5.B2',\n",
      "       u'BPM.8L5.B2', u'BPMR.6L5.B2', u'BPMWT.B6L5.B2', u'BPMWT.A6L5.B2',\n",
      "       u'BPMWT.D6L5.B2', u'BPMWT.C6L5.B2', u'BPM.5L5.B2', u'BPMYA.4L5.B2',\n",
      "       u'BPMWB.4L5.B2', u'BPMS.2L5.B2'],\n",
      "      dtype='object') Index([u'BPMSW.1R5.B1', u'BPMS.2R5.B1', u'BPMWB.4R5.B1', u'BPMYA.4R5.B1',\n",
      "       u'BPM.5R5.B1', u'BPMWT.C6R5.B1', u'BPMWT.D6R5.B1', u'BPMWT.A6R5.B1',\n",
      "       u'BPMWT.B6R5.B1', u'BPMR.6R5.B1', u'BPM_A.7R5.B1', u'BPM.8R5.B1',\n",
      "       u'BPM.9R5.B1', u'BPM.10R5.B1', u'BPM.11R5.B1', u'BPM.12R5.B1',\n",
      "       u'BPM.13R5.B1', u'BPM.14R5.B1', u'BPM.15R5.B1', u'BPM.16R5.B1',\n",
      "       u'BPM.17R5.B1', u'BPM.18R5.B1', u'BPM.19R5.B1', u'BPM.20R5.B1',\n",
      "       u'BPM.21R5.B1', u'BPM.22R5.B1', u'BPM.23R5.B1', u'BPM.24R5.B1',\n",
      "       u'BPM.25R5.B1', u'BPM.26R5.B1', u'BPM.27R5.B1', u'BPM.28R5.B1',\n",
      "       u'BPM.29R5.B1', u'BPM.30R5.B1', u'BPM.31R5.B1', u'BPM.32R5.B1',\n",
      "       u'BPM.33R5.B1', u'BPM.34R5.B1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#  transforming the data\n",
    "# ---------------------\n",
    "selectionred = fill.getbpmhreduced()\n",
    "\n",
    "# selecting bpm right and left of ip5\n",
    "bpmr5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R5.B1')])]\n",
    "bpml5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L5.B2')])]\n",
    "\n",
    "\n",
    "tfsb1 =pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfsb1 = tfsb1[tfsb1['NAME']!='%s']\n",
    "colsb1 = list(tfsb1.columns[1:])\n",
    "tfsb1 = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R5.B1'))]\n",
    "tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "namesr = list(bpmr5test.columns)\n",
    "\n",
    "# [[float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]),bpmr5test[n][0]] for n in namesr]\n",
    "# (fill4696.bpmdf['t'].tail(50)-fill4696.bpmdf['t'].head(1).values)/3600000\n",
    "bpmr5test.tail(50)\n",
    "\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfs = tfs[tfs['NAME']!='%s']\n",
    "cols = list(tfs.columns[1:])\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(46),delim_whitespace=True,names=cols,index_col=False)\n",
    "tfs = tfs[tfs['S']!='%s']\n",
    "tfsbpm= tfs[(tfs['NAME'].str.contains('BPM')) & (tfs['NAME'].str.contains('L5.B2'))]\n",
    "tfsbpm = tfsbpm[1:]\n",
    "tfsbpm = tfsbpm[['NAME','S']]\n",
    "names = list(bpml5test.columns)\n",
    "\n",
    "print bpml5test.columns, bpmr5test.columns\n",
    "# (fill.bpmdf['t'].tail(100)-fill.bpmdf['t'].head(2).values[1])/3600000\n",
    "# dfmask[range(1,1089)][dfmask[range(1,1089)].sum(axis=1).values>1.].tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -20381.90\n",
       "1       -20381.90\n",
       "2       -20381.90\n",
       "3       -20381.90\n",
       "4       -20381.90\n",
       "5       -20381.90\n",
       "6       -20381.90\n",
       "7       -20381.90\n",
       "8       -20381.90\n",
       "9       -20381.90\n",
       "10      -20381.90\n",
       "11      -20381.90\n",
       "12      -20381.90\n",
       "13      -20381.90\n",
       "14      -20381.90\n",
       "15      -20381.90\n",
       "16      -20381.90\n",
       "17      -20381.90\n",
       "18      -20381.90\n",
       "19      -20381.90\n",
       "20      -20381.90\n",
       "21      -20381.90\n",
       "22      -20381.90\n",
       "23      -20381.90\n",
       "24      -20381.90\n",
       "25      -20381.90\n",
       "26      -20381.90\n",
       "27      -20381.90\n",
       "28      -20381.90\n",
       "29      -20381.90\n",
       "           ...   \n",
       "10359    -2690.81\n",
       "10360    -2690.81\n",
       "10361    -2690.81\n",
       "10362    -2690.81\n",
       "10363    -2690.81\n",
       "10364    -2690.81\n",
       "10365    -2690.81\n",
       "10366    -2690.81\n",
       "10367    -2690.81\n",
       "10368    -2690.81\n",
       "10369    -2690.81\n",
       "10370    -2690.81\n",
       "10371    -2690.81\n",
       "10372    -2690.81\n",
       "10373    -2690.81\n",
       "10374    -2690.81\n",
       "10375    -2690.81\n",
       "10376    -2690.81\n",
       "10377    -2690.81\n",
       "10378    -2690.81\n",
       "10379    -2690.81\n",
       "10380    -2690.81\n",
       "10381    -2690.81\n",
       "10382    -2690.81\n",
       "10383    -2690.81\n",
       "10384    -2690.81\n",
       "10385    -2690.81\n",
       "10386    -2690.81\n",
       "10387    -2690.81\n",
       "10388    -2690.81\n",
       "Name: BPM.11R5.B1, dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcopy = pd.DataFrame(fill.bpmhmask[range(1,1089)][fill.bpmhmask[range(1,1089)].sum(axis=1).values>1.].tail(1).values, \n",
    "                              columns =  fill.bpmdf.drop(fill.bpmdf.columns[0],axis=1).columns)\n",
    "dfcopy['BPM.11R5.B1']\n",
    "dfcopy.iloc[0]['BPM.11R5.B1']\n",
    "dffff = fill.bpmdf.drop(fill.bpmdf.columns[0],axis=1)\n",
    "ss = dffff.multiply(dfcopy.iloc[0],axis=1)\n",
    "ss = dffff[(dffff>1.0)| (dffff< -1.0)]#.dropna(axis=1)\n",
    "# ss.dropna(axis=1,how='all')\n",
    "# ['BPM.11R5.B1']\n",
    "# dffff['BPMWF.A1R1.B1']\n",
    "ss['BPMWF.A1R1.B1']\n",
    "td = dffff * dfcopy.iloc[0]\n",
    "td2 = td[(td>1.0)| (td< -1.0)]\n",
    "td3 = td2.dropna(axis=1)\n",
    "td2['BPM.11R5.B1']\n",
    "td2.dropna(axis=1,how='all')['BPM.11R5.B1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fill4696.bpmdf.columns).index('BPM.11R5.B1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0,max=len(bpmr5test)+len(bpmr5test) )\n",
    "display(f)\n",
    "\n",
    "fig = plt.figure(figsize=(18,20))\n",
    "ax = fig.add_subplot(211)\n",
    "\n",
    "s1 = np.array([float(tfsbpm[tfsbpm['NAME']==n]['S'].values[0]) for n in names])\n",
    "max1 = len(bpml5test)\n",
    "nn = 1000\n",
    "step = 20\n",
    "for i in range(0,len(bpml5test.tail(nn)),step):\n",
    "    data = np.array([bpml5test[n][max1-nn+i] for n in names])\n",
    "    plt.scatter(s1,data)\n",
    "    plt.plot(s1,data)\n",
    "    f.value = i\n",
    "plt.plot((0,500),(500,500),'k-')\n",
    "plt.plot((0,500),(-500,-500),'k-')\n",
    "plt.plot((0,500),(-3000,-3000),'k-')\n",
    "plt.plot((0,500),(-3500,-3500),'k-')\n",
    "plt.plot((0,500),(0,0),'k-')\n",
    "plt.grid()\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(-10000,5000)\n",
    "ax.set_xticks(np.arange(0,500,100))\n",
    "ax.set_xticks(np.arange(0,500,10),minor=True)\n",
    "ax.set_yticks(np.arange(-10000,5000,2000))\n",
    "ax.set_yticks(np.arange(-10000,5000,500),minor=True)\n",
    "ax.grid(which='minor',alpha=0.2)\n",
    "plt.xlabel('s [m from IP5]',fontsize=16.0)\n",
    "plt.ylabel('x [um]')\n",
    "plt.title('BPM orbits Horizontal left of IP5 - fill 4707 ')\n",
    "ax.text(100,4000, 'Each line (colour) is at a different timestamp.')\n",
    "ax.annotate('roughly 0.5 mm below \\n 3mm from bump',xy=(440,-3400),xytext=(400,-5000),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.5))\n",
    "ax.plot([440],[500],'o')\n",
    "ax.annotate('Expected with 0.5 mm bump',xy=(440,500),xytext=(400,2500),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "max2 = len(bpmr5test)\n",
    "s2 = np.array([float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]) for n in namesr])\n",
    "for i in range(0,len(bpmr5test.tail(nn)),step):\n",
    "    data =  np.array([bpmr5test[n][max2-nn+i] for n in namesr])\n",
    "    ax2.scatter(s2,data)\n",
    "    ax2.plot(s2,data)\n",
    "    f.value = f.value +1 \n",
    "plt.plot((0,500),(500,500),'k-')\n",
    "plt.plot((0,500),(-500,-500),'k-')\n",
    "plt.plot((0,500),(-3000,-3000),'k-')\n",
    "plt.plot((0,500),(-3500,-3500),'k-')\n",
    "plt.plot((0,500),(0,0),'k-')\n",
    "plt.grid()\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(-10000,5000)\n",
    "ax2.set_xticks(np.arange(0,500,100))\n",
    "ax2.set_xticks(np.arange(0,500,10),minor=True)\n",
    "ax2.set_yticks(np.arange(-10000,5000,2000))\n",
    "ax2.set_yticks(np.arange(-10000,5000,500),minor=True)\n",
    "ax2.grid(which='minor',alpha=0.2)\n",
    "ax2.annotate('roughly 0.5 mm above \\n 3mm from bump',xy=(433,-2650),xytext=(400,-5000),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "plt.xlabel('s [m from IP5]',fontsize=16.0)\n",
    "plt.ylabel('x [um]')\n",
    "plt.title('BPM orbits Horizontal right of IP5  - fill 4707 ')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('Fill4707IP5bpm.png',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEEAAASBCAYAAADbiYBgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8448b86990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0,max=len(bpml5) )\n",
    "display(f)\n",
    "f.value=0\n",
    "fig = plt.figure(figsize=(18,20))\n",
    "mymap = plt.get_cmap('jet')\n",
    "norm = plt.Normalize()\n",
    "norm.autoscale(np.linspace(0,len(bpml5),len(bpml5)))\n",
    "for i in range(len(bpml5)):\n",
    "    plt.scatter(bpml5['BPM.7L5.B2'][i],bpml5['BPM.11L5.B2'][i],color=mymap(float(i)/len(bpml5)))\n",
    "    f.value = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe mask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAA</th>\n",
       "      <th>BBB</th>\n",
       "      <th>CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAA  BBB  CCC\n",
       "0    4   10  100\n",
       "1    5   20   50\n",
       "2    6   30  -30\n",
       "3    7   40  -50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfex = pd.DataFrame({'AAA' :[4,5,6,7],'BBB':[10,20,30,40],'CCC':[100,50,-30,-50]});dfex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAA</th>\n",
       "      <th>BBB</th>\n",
       "      <th>CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AAA    BBB    CCC\n",
       "0  True  False   True\n",
       "1  True  False  False\n",
       "2  True  False   True\n",
       "3  True  False  False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfex_mask = pd.DataFrame({'AAA':[True] *4,'BBB':[False]*4,'CCC':[True,False]*2});dfex_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAA</th>\n",
       "      <th>BBB</th>\n",
       "      <th>CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAA  BBB  CCC\n",
       "0    4    0  100\n",
       "1    5    0    0\n",
       "2    6    0  -30\n",
       "3    7    0    0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfex.where(dfex_mask,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f847b2b7090>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEXCAYAAABPkyhHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f847b254710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfex.where(dfex_mask,0).plot(x='AAA',y='CCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAA</th>\n",
       "      <th>BBB</th>\n",
       "      <th>CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAA  BBB  CCC\n",
       "0  0.1   10  100\n",
       "1  0.1   20   50\n",
       "2  6.0   30  -30\n",
       "3  7.0   40  -50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfex.loc[(dfex['BBB']<=0) | (dfex['CCC'] >0),'AAA']=0.1;dfex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf = pd.Panel({'dfs':tfsbpmr,'dfbpm':bpmr5})\n",
    "pf.ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>PARENT</th>\n",
       "      <th>S</th>\n",
       "      <th>L</th>\n",
       "      <th>LRAD</th>\n",
       "      <th>KICK</th>\n",
       "      <th>HKICK</th>\n",
       "      <th>VKICK</th>\n",
       "      <th>ANGLE</th>\n",
       "      <th>...</th>\n",
       "      <th>DPX</th>\n",
       "      <th>DPY</th>\n",
       "      <th>KMAX</th>\n",
       "      <th>KMIN</th>\n",
       "      <th>CALIB</th>\n",
       "      <th>POLARITY</th>\n",
       "      <th>APERTYPE</th>\n",
       "      <th>APER_1</th>\n",
       "      <th>N1</th>\n",
       "      <th>TILT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>MQ.11L5.B2</td>\n",
       "      <td>QUADRUPOLE</td>\n",
       "      <td>MQ</td>\n",
       "      <td>438.8146576</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03990041431</td>\n",
       "      <td>-0.001215973403</td>\n",
       "      <td>223</td>\n",
       "      <td>6.575</td>\n",
       "      <td>0.01878685762</td>\n",
       "      <td>1</td>\n",
       "      <td>CIRCLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NAME     KEYWORD PARENT            S    L LRAD KICK HKICK VKICK  \\\n",
       "218  MQ.11L5.B2  QUADRUPOLE     MQ  438.8146576  3.1    0    0     0     0   \n",
       "\n",
       "    ANGLE ...             DPX              DPY KMAX   KMIN          CALIB  \\\n",
       "218     0 ...   0.03990041431  -0.001215973403  223  6.575  0.01878685762   \n",
       "\n",
       "    POLARITY APERTYPE APER_1 N1 TILT  \n",
       "218        1   CIRCLE      0  0    0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = tfs[tfs[\"NAME\"]=='MQ.11L5.B2']\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `TimberGetDataClass.py`:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "from matplotlib import pyplot as plt\n",
      "import csv\n",
      "import glob\n",
      "import datetime\n",
      "import collections\n",
      "import time\n",
      "import subprocess\n",
      "import os\n",
      "from scipy import optimize as opt\n",
      "from scipy import constants as const\n",
      "from StringIO import StringIO\n",
      "from matplotlib import rc,rcParams\n",
      "from matplotlib.patches import Rectangle\n",
      "import itertools\n",
      "\n",
      "# simdata\n",
      "from pandas.tools.plotting import autocorrelation_plot\n",
      "from pandas.tools.plotting import lag_plot\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "\n",
      "class LHCfill(object):\n",
      "    # names of timberdata we want to extract\n",
      "    timbervarFBCTB1    = 'LHC.BCTFR.A6R4.B1:BUNCH_INTENSITY'\n",
      "    timbervarFBCTB2    = 'LHC.BCTFR.A6R4.B2:BUNCH_INTENSITY'\n",
      "\n",
      "    timbervarBQMB1L   = 'LHC.BQM.B1:BUNCH_LENGTHS'\n",
      "    timbervarBQMB1F   = 'LHC.BQM.B1:FILLED_BUCKETS'\n",
      "\n",
      "    timbervarBQMB2L   = 'LHC.BQM.B2:BUNCH_LENGTHS'\n",
      "    timbervarBQMB2F   = 'LHC.BQM.B2:FILLED_BUCKETS'\n",
      "\n",
      "    timbervarBSRTB1H  = 'LHC.BSRT.5R4.B1:FIT_SIGMA_H'\n",
      "    timbervarBSRTB1V  = 'LHC.BSRT.5R4.B1:FIT_SIGMA_V'\n",
      "    timbervarBSRTB1GD = 'LHC.BSRT.5R4.B1:GATE_DELAY'\n",
      "    timbervarBSRTB1CH = 'LHC.BSRT.5R4.B1:LSF_H'\n",
      "    timbervarBSRTB1CV = 'LHC.BSRT.5R4.B1:LSF_V'\n",
      "\n",
      "    timbervarBSRTB2H  = 'LHC.BSRT.5L4.B2:FIT_SIGMA_H'\n",
      "    timbervarBSRTB2V  = 'LHC.BSRT.5L4.B2:FIT_SIGMA_V'\n",
      "    timbervarBSRTB2GD = 'LHC.BSRT.5L4.B2:GATE_DELAY'\n",
      "    timbervarBSRTB2CH = 'LHC.BSRT.5L4.B2:LSF_H'\n",
      "    timbervarBSRTB2CV = 'LHC.BSRT.5L4.B2:LSF_V'\n",
      "\n",
      "    timbervarLumiAtlas = \"ATLAS:LUMI_TOT_INST\"\n",
      "    timbervarLumiAlice = \"ALICE:LUMI_TOT_INST\"\n",
      "    timbervarLumiCMS   = \"CMS:LUMI_TOT_INST\"\n",
      "    timbervarLumiLHCB  = \"LHCB:LUMI_TOT_INST\"\n",
      "    \n",
      "    timbervarhorbpm = 'LHC.BOFSU:POSITIONS_H'\n",
      "\n",
      "    # constants\n",
      "    protonmass = const.physical_constants['proton mass energy equivalent in MeV'][0]/1000 # GeV\n",
      "    ionA       = 208.\n",
      "    ionZ       = 82.\n",
      "    energy     = 6370\n",
      "    gamma      = energy * ionZ / 193.7291748489224\n",
      "\n",
      "    # beta's for the undulators and dipoles for the bsrt light\n",
      "    betaUndH = [203.,200.]\n",
      "    betaUndV = [318.,327.]\n",
      "    betaDipH = [214., 205.]\n",
      "    betaDipV = [328.,344.]\n",
      "    \n",
      "    def __init__(self,fillnumber,basedir):\n",
      "        self.fillnumber = fillnumber\n",
      "        self.basedir    = basedir\n",
      "        self.summarydf, self.summaryfile    = self.getsummary()\n",
      "        self.bunchlenb1df, self.bunch2enb1df = self.getbunchlenghts('Fill' + str(self.fillnumber) + 'BLb1',\n",
      "                                                                    'Fill' + str(self.fillnumber) + 'BLb2')\n",
      "        self.ex1df,self.ey1df,self.ex2df,self.ey2df = self.getemitbsrt('Fill' + str(self.fillnumber) +'emit1','Fill' + str(self.fillnumber)+'emit2') \n",
      "        self.I1df,self.I2df = self.getFBCT('Fill' + str(self.fillnumber) +'fbct1','Fill' + str(self.fillnumber)+'fbct2')\n",
      "        self.lumiatlasdf,self.lumicmsdf,self.lumialicedf,self.lumilhcbdf = self.getlumi('Fill' + str(self.fillnumber) +'atlas','Fill' + str(self.fillnumber)+'cms',\n",
      "            'Fill' + str(self.fillnumber) +'alice','Fill' + str(self.fillnumber)+'lhcb')\n",
      "        self.bpmdf = self.gethorbpm('Fill' + str(self.fillnumber) +'bpmH')\n",
      "        \n",
      "    def getsummary(self):\n",
      "        infn   = \"Fill\" + str(self.fillnumber) + \"Summary\"\n",
      "        outfn  = self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\"\n",
      "        bashcmd1 = \"./cern-mdb -M FD -fn \" + str(self.fillnumber) + \" -N  \" + infn + \" -F CSV\"\n",
      "        bashcmd2 = \"mv \" + infn + \".CSV \" + outfn\n",
      "        subprocess.call(bashcmd1,shell=True)\n",
      "        subprocess.call(bashcmd2,shell=True)\n",
      "        dfsummary = pd.read_csv(outfn,delimiter=',',header=0)\n",
      "        return dfsummary, outfn+\".CSV\"\n",
      "    \n",
      "    # def convert to unix time\n",
      "    def converttimetounix(self,t):\n",
      "        return time.mktime(datetime.datetime.strptime(t,\"%Y-%m-%d %H:%M:%S.%f\").timetuple())\n",
      "    \n",
      "    def addtime(self,intime,deltahour):\n",
      "        mytime = datetime.datetime.strptime(intime,\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "        mytime += datetime.timedelta(hours=deltahour)\n",
      "        return mytime.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
      "    # returns start time of fill\n",
      "    def gettimes(self):\n",
      "        timesodic = collections.OrderedDict()\n",
      "        if os.path.isfile(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\"):\n",
      "            startdf = pd.read_csv(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\",\n",
      "                                  delimiter=',',header=0)\n",
      "            dc = collections.OrderedDict()\n",
      "            for name, group in startdf.groupby('Value'):\n",
      "                starttimes = group['StartTime(UTC_TIME)'].values\n",
      "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
      "                arr = np.array([starttimes,stoptimes])\n",
      "                dc[name] = np.transpose(arr)\n",
      "            return dc\n",
      "        else:\n",
      "            self.getsummary()\n",
      "            startdf = pd.read_csv(self.basedir + \"/Fill\" + str(self.fillnumber) + \"Summary.CSV\",\n",
      "                                  delimiter=',',header=0)\n",
      "            dc = collections.OrderedDict()\n",
      "            for name, group in startdf.groupby('Value'):\n",
      "                starttimes = group['StartTime(UTC_TIME)'].values\n",
      "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
      "                arr = np.array([starttimes,stoptimes])\n",
      "                dc[name] = np.transpose(arr)\n",
      "            return dc\n",
      "        \n",
      "    def getbunchpositions(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        \n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "            shcmdBQMFB1 = './cern-ldb -vs ' + self.timbervarBQMB1F + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            shcmdBQMFB2 = './cern-ldb -vs ' + self.timbervarBQMB2F + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "#             print shcmdBQMFB1\n",
      "            try:\n",
      "                subprocess.call(shcmdBQMFB1,shell=True)\n",
      "                subprocess.call(shcmdBQMFB2,shell=True)\n",
      "\n",
      "                bashcmd1 = \"mv \" + fnb1 + \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 + \".CSV \" + outfn2\n",
      "\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "\n",
      "                fileexist = True\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "                \n",
      "        if fileexist:\n",
      "            b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            return [int((i-1.)/10.) for i in b1bunchdata[range(1,3565)][b1bunchdata[range(1,3565)].sum(axis=1).values>0.1].tail(1).values[0] if i >0.1],                [int((i-1.)/10.) for i in b2bunchdata[range(1,3565)][b2bunchdata[range(1,3565)].sum(axis=1).values>0.1].tail(1).values[0] if i >0.1]\n",
      "        else:  \n",
      "            print 'Something went wrong, no data loaded.'\n",
      "        \n",
      "    def getbunchlenghts(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "            shcmdBQMLB1 = './cern-ldb -vs ' + self.timbervarBQMB1L + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            shcmdBQMLB2 = './cern-ldb -vs ' + self.timbervarBQMB2L + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +                            stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "#             print shcmdBQMFB1\n",
      "            try:\n",
      "                subprocess.call(shcmdBQMLB1,shell=True)\n",
      "                subprocess.call(shcmdBQMLB2,shell=True)\n",
      "\n",
      "                bashcmd1 = \"mv \" + fnb1 + \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 + \".CSV \" + outfn2\n",
      "\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "\n",
      "                fileexist = True\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "                \n",
      "        if fileexist:\n",
      "            b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,skiprows=[0,1,2])\n",
      "            bposb1, bposb2 = self.getbunchpositions(fnb1+'pos',fnb2+'pos')\n",
      "            bposb1[:0]=[0]\n",
      "            bposb2[:0]=[0]\n",
      "            return b1bunchdata[bposb1],b2bunchdata[bposb2]\n",
      "        else:  \n",
      "            print 'Something went wrong, no data loaded.'\n",
      "            \n",
      "    def bsrtsigfromraw(self,bsrtgdreader,bsrtsighreader,bsrtsigvreader,bsrtzerotime):\n",
      "        exdict = collections.OrderedDict()\n",
      "        eydict = collections.OrderedDict()\n",
      "        \n",
      "        \n",
      "        # get end of ramp for switching betas\n",
      "        tdc = self.gettimes()\n",
      "        rampend = tdc['RAMP'][-1][-1]\n",
      "        rampend = self.converttimetounix(rampend)\n",
      "\n",
      "        for lhs,rhs,rrhs in itertools.izip(bsrtgdreader,bsrtsighreader,bsrtsigvreader):\n",
      "                # skip over the headers\n",
      "                if len(lhs) > 4:\n",
      "                    # since the BSRT light is either generated at the undulator or the dipole,\n",
      "                    # we have to select which beta is used \n",
      "                    if (int(lhs[0]) <= rampend):\n",
      "                        beta = self.betaUndH[0]\n",
      "                    else:\n",
      "                        beta = self.betaDipH[0]\n",
      "                    # looping through the columns of a row in the csv files\n",
      "                    for i in range(1,len(lhs)):\n",
      "                        # check if the key is already present in the output dictionary\n",
      "                        if int(float(lhs[i])) in exdict.keys():\n",
      "                            excomputed = self.gamma * float(rhs[i])**2/beta\n",
      "                            exdict[int(float(lhs[i]))].append([(int(lhs[0])-bsrtzerotime)/3600000.,excomputed])\n",
      "                        else:\n",
      "                            excomputed = self.gamma * float(rhs[i])**2/beta\n",
      "                            exdict[int(float(lhs[i]))]=[[(int(lhs[0])-bsrtzerotime)/3600000.,excomputed]]\n",
      "                        if int(float(lhs[i])) in eydict.keys():\n",
      "                            eycomputed = self.gamma * float(rrhs[i])**2/beta\n",
      "                            eydict[int(float(lhs[i]))].append([(int(lhs[0])-bsrtzerotime)/3600000.,eycomputed])\n",
      "                        else:\n",
      "                            eycomputed = self.gamma * float(rrhs[i])**2/beta\n",
      "                            eydict[int(float(lhs[i]))]=[[(int(lhs[0])-bsrtzerotime)/3600000.,eycomputed]]\n",
      "        return exdict,eydict\n",
      "    \n",
      "    def convertdicttodf(self,dictin):\n",
      "        dflist        = [pd.DataFrame(np.array(dictin[i]),columns=[0,i]) for i in dictin.keys()]\n",
      "        dflistgrouped = [dflist[i].groupby(0,as_index=False).mean() for i in range(len(dflist))]\n",
      "        dffinal       = reduce(lambda left,right: pd.merge(left,right,on=0,how='outer'),dflistgrouped)\n",
      "        dffinal2      = dffinal.fillna(0)\n",
      "        cols          = dffinal.columns\n",
      "        return dffinal2.loc[(dffinal2[cols[1:]]!=0).any(1)]\n",
      "    \n",
      "    def getemitbsrt(self,fnb1,fnb2):\n",
      "        if (os.path.isfile(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')):\n",
      "            ex1dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')\n",
      "            ey1dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY1.CSV')\n",
      "            ex2dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX2.CSV')\n",
      "            ey2dfout = pd.read_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY2.CSV')\n",
      "            return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
      "        else:\n",
      "            tdc = self.gettimes()\n",
      "            fileexist = False\n",
      "            outfn1  = self.basedir + \"/\" + fnb1 + 'sigh' + \".CSV\"\n",
      "            outfn2  = self.basedir + \"/\" + fnb1 + 'sigv' + \".CSV\"\n",
      "            outfn3  = self.basedir + \"/\" + fnb1 + 'gdh' + \".CSV\"\n",
      "            outfn4  = self.basedir + \"/\" + fnb1 + 'corh' + \".CSV\"\n",
      "            outfn5  = self.basedir + \"/\" + fnb1 + 'corv' + \".CSV\"\n",
      "            outfn6  = self.basedir + \"/\" + fnb2 + 'sigh' + \".CSV\"\n",
      "            outfn7  = self.basedir + \"/\" + fnb2 + 'sigv' + \".CSV\"\n",
      "            outfn8  = self.basedir + \"/\" + fnb2 + 'gdh' + \".CSV\"\n",
      "            outfn9  = self.basedir + \"/\" + fnb2 + 'corh' + \".CSV\"\n",
      "            outfn10  = self.basedir + \"/\" + fnb2 + 'corv' + \".CSV\"\n",
      "            if (os.path.isfile(self.basedir + '/' + fnb1 + 'sigh' + '.CSV')) and                    (os.path.isfile(self.basedir + '/' + fnb2  + 'sigh' + '.CSV')):\n",
      "                fileexist = True\n",
      "            else:\n",
      "                stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "                start = tdc[str(self.fillnumber)][-1][0]\n",
      "\n",
      "                bashcmdBSRTSIGHB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1H + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'sigh' + ' -F CSV'\n",
      "                bashcmdBSRTSIGVB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1V + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'sigv' + ' -F CSV'\n",
      "                bashcmdBSRTGDHB1  = './cern-ldb -vs ' +  self.timbervarBSRTB1GD + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'gdh' + ' -F CSV'\n",
      "                bashcmdBSRTCORHB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1CH + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'corh' + ' -F CSV'\n",
      "                bashcmdBSRTCORVB1 = './cern-ldb -vs ' +  self.timbervarBSRTB1CV + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + 'corv' + ' -F CSV'\n",
      "\n",
      "                bashcmdBSRTSIGHB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2H + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'sigh' + ' -F CSV'\n",
      "                bashcmdBSRTSIGVB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2V + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'sigv' + ' -F CSV'\n",
      "                bashcmdBSRTGDHB2  = './cern-ldb -vs ' +  self.timbervarBSRTB2GD + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'gdh' + ' -F CSV'\n",
      "                bashcmdBSRTCORHB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2CH + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'corh' + ' -F CSV'\n",
      "                bashcmdBSRTCORVB2 = './cern-ldb -vs ' +  self.timbervarBSRTB2CV + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + 'corv' + ' -F CSV'\n",
      "\n",
      "                try:\n",
      "                    subprocess.call(bashcmdBSRTSIGHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTSIGVB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTGDHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORHB1,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORVB1,shell=True)\n",
      "\n",
      "                    subprocess.call(bashcmdBSRTSIGHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTSIGVB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTGDHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORHB2,shell=True)\n",
      "                    subprocess.call(bashcmdBSRTCORVB2,shell=True)\n",
      "\n",
      "                    bashcmd1 = \"mv \" + fnb1 + 'sigh' + \".CSV \" + outfn1\n",
      "                    bashcmd2 = \"mv \" + fnb1 + 'sigv' + \".CSV \" + outfn2\n",
      "                    bashcmd3 = \"mv \" + fnb1 + 'gdh'  + \".CSV \" + outfn3\n",
      "                    bashcmd4 = \"mv \" + fnb1 + 'corh' + \".CSV \" + outfn4\n",
      "                    bashcmd5 = \"mv \" + fnb1 + 'corv' + \".CSV \" + outfn5\n",
      "\n",
      "                    bashcmd6 = \"mv \" + fnb2 + 'sigh' + \".CSV \" + outfn6\n",
      "                    bashcmd7 = \"mv \" + fnb2 + 'sigv' + \".CSV \" + outfn7\n",
      "                    bashcmd8 = \"mv \" + fnb2 + 'gdh'  + \".CSV \" + outfn8\n",
      "                    bashcmd9 = \"mv \" + fnb2 + 'corh' + \".CSV \" + outfn9\n",
      "                    bashcmd10 = \"mv \" + fnb2 + 'corv' + \".CSV \" + outfn10\n",
      "\n",
      "                    subprocess.call(bashcmd1,shell=True)\n",
      "                    subprocess.call(bashcmd2,shell=True)\n",
      "                    subprocess.call(bashcmd3,shell=True)\n",
      "                    subprocess.call(bashcmd4,shell=True)\n",
      "                    subprocess.call(bashcmd5,shell=True)\n",
      "                    subprocess.call(bashcmd6,shell=True)\n",
      "                    subprocess.call(bashcmd7,shell=True)\n",
      "                    subprocess.call(bashcmd8,shell=True)\n",
      "                    subprocess.call(bashcmd9,shell=True)\n",
      "                    subprocess.call(bashcmd10,shell=True)\n",
      "\n",
      "                    fileexist = True\n",
      "                except:\n",
      "                    print 'Loading of data failed.'\n",
      "            if fileexist:\n",
      "                # opening the files\n",
      "                fgdb1   = open(outfn3,'rU')\n",
      "                fsighb1 = open(outfn1,'rU')\n",
      "                fsigvb1 = open(outfn2,'rU')\n",
      "\n",
      "                fgdb2   = open(outfn8,'rU')\n",
      "                fsighb2 = open(outfn6,'rU')\n",
      "                fsigvb2 = open(outfn7,'rU')\n",
      "\n",
      "                # creating the csv_reader objects\n",
      "                bsrtgdb1reader = csv.reader(fgdb1)\n",
      "                bsrtsighb1reader = csv.reader(fsighb1)\n",
      "                bsrtsigvb1reader = csv.reader(fsigvb1)\n",
      "\n",
      "                bsrtgdb2reader = csv.reader(fgdb2)\n",
      "                bsrtsighb2reader = csv.reader(fsighb2)\n",
      "                bsrtsigvb2reader = csv.reader(fsigvb2)\n",
      "\n",
      "                # creating a variable containing the zero time moment\n",
      "                rowlist      = [row for row in bsrtgdb1reader]\n",
      "                bsrtzerotime = int(rowlist[3][0])\n",
      "\n",
      "                rowlistb2      = [row for row in bsrtgdb2reader]\n",
      "                bsrtzerotimeb2 = int(rowlistb2[3][0])\n",
      "\n",
      "                # reloading the GD file and recreating the csv_reader object since it has been used (Pointers!!!)\n",
      "                fgdb1 =open(outfn3,'rU')\n",
      "                bsrtgdb1reader = csv.reader(fgdb1)\n",
      "\n",
      "                fgdb2 =open(outfn8,'rU')\n",
      "                bsrtgdb2reader = csv.reader(fgdb2)\n",
      "\n",
      "                # initializing the dictionary that will contain the processed data\n",
      "                # keys are the bunchslot numbers\n",
      "                # values are a list of 2D lists that contain a timestamp and the normalized emittance at that time\n",
      "                exb1dict = collections.OrderedDict()\n",
      "                eyb1dict = collections.OrderedDict()\n",
      "                exb2dict = collections.OrderedDict()\n",
      "                eyb2dict = collections.OrderedDict()\n",
      "\n",
      "                exb1dict,eyb1dict = self.bsrtsigfromraw(bsrtgdb1reader,bsrtsighb1reader,bsrtsigvb1reader,bsrtzerotime)\n",
      "                exb2dict,eyb2dict = self.bsrtsigfromraw(bsrtgdb2reader,bsrtsighb2reader,bsrtsigvb2reader,bsrtzerotimeb2)\n",
      "\n",
      "                bashcmd1 = \"rm \" + outfn1\n",
      "                bashcmd2 = \"rm \" + outfn2\n",
      "                bashcmd3 = \"rm \" + outfn3\n",
      "                bashcmd4 = \"rm \" + outfn4\n",
      "                bashcmd5 = \"rm \" + outfn5\n",
      "\n",
      "                bashcmd6 = \"rm \" + outfn6\n",
      "                bashcmd7 = \"rm \" + outfn7\n",
      "                bashcmd8 = \"rm \" + outfn8\n",
      "                bashcmd9 = \"rm \" + outfn9\n",
      "                bashcmd10 = \"rm \" + outfn10\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                subprocess.call(bashcmd3,shell=True)\n",
      "                subprocess.call(bashcmd4,shell=True)\n",
      "                subprocess.call(bashcmd5,shell=True)\n",
      "                subprocess.call(bashcmd6,shell=True)\n",
      "                subprocess.call(bashcmd7,shell=True)\n",
      "                subprocess.call(bashcmd8,shell=True)\n",
      "                subprocess.call(bashcmd9,shell=True)\n",
      "                subprocess.call(bashcmd10,shell=True)\n",
      "                \n",
      "                ex1dfout =self.convertdicttodf(exb1dict)\n",
      "                ey1dfout =self.convertdicttodf(eyb1dict)\n",
      "                ex2dfout =self.convertdicttodf(exb2dict)\n",
      "                ey2dfout =self.convertdicttodf(eyb2dict)\n",
      "        \n",
      "                ex1dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX1.CSV')\n",
      "                ey1dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY1.CSV')\n",
      "                ex2dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EX2.CSV')\n",
      "                ey2dfout.to_csv(self.basedir + \"/\" + 'Fill' + str(self.fillnumber) + 'EY2.CSV')\n",
      "                \n",
      "                return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
      "            else:\n",
      "                print 'Something went wrong, no data loaded'\n",
      "                \n",
      "    def getFBCT(self,fnb1,fnb2):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn1  = self.basedir + \"/\" + fnb1 + \".CSV\"\n",
      "        outfn2  = self.basedir + \"/\" + fnb2 + \".CSV\"\n",
      "        \n",
      "        cols1,cols2 = self.getbunchpositions(fnb1+'pos',fnb2+'pos')\n",
      "        cols1 = [i + 1 for i in cols1]\n",
      "        cols2 = [i + 1 for i in cols2]\n",
      "        cols1[:0] = [0]\n",
      "        cols2[:0] = [0]\n",
      "        \n",
      "        if (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')) and                (os.path.isfile(self.basedir + '/' + fnb1 + '.CSV')):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            \n",
      "            bashcmdFBCTB1 = './cern-ldb -vs ' +  self.timbervarFBCTB1 + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb1 + ' -F CSV'\n",
      "            bashcmdFBCTB2 = './cern-ldb -vs ' +  self.timbervarFBCTB2 + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnb2 + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdFBCTB1,shell=True)\n",
      "                subprocess.call(bashcmdFBCTB2,shell=True)\n",
      "                \n",
      "                bashcmd1 = \"mv \" + fnb1 +  \".CSV \" + outfn1\n",
      "                bashcmd2 = \"mv \" + fnb2 +  \".CSV \" + outfn2\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                fileexist = True\n",
      "            \n",
      "                b1bunchdata = pd.read_csv(outfn1,delimiter=',',header=None,names=range(3565),\n",
      "                                          skiprows=[0,1,2],usecols=cols1)\n",
      "                b2bunchdata = pd.read_csv(outfn2,delimiter=',',header=None,names=range(3565),\n",
      "                                          skiprows=[0,1,2],usecols=cols2)\n",
      "                b1bunchdata.columns = [i-1 if i !=0 else 0 for i in cols1]\n",
      "                b2bunchdata.columns = [i-1 if i !=0 else 0 for i in cols2]\n",
      "                b1bunchdata.to_csv(outfn1,index=None)\n",
      "                b2bunchdata.to_csv(outfn2,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            \n",
      "            b1bunchdata = pd.read_csv(outfn1)\n",
      "            b2bunchdata = pd.read_csv(outfn2)\n",
      "            return b1bunchdata,b2bunchdata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "    \n",
      "    def getlumi(self,fnatlas,fncms,fnalice,fnlhcb):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfnatlas  = self.basedir + \"/\" + fnatlas + \".CSV\"\n",
      "        outfncms    = self.basedir + \"/\" + fncms   + \".CSV\"\n",
      "        outfnalice  = self.basedir + \"/\" + fnalice + \".CSV\"\n",
      "        outfnlhcb   = self.basedir + \"/\" + fnlhcb  + \".CSV\"        \n",
      "        \n",
      "        if os.path.isfile(self.basedir + '/' + fnatlas + '.CSV'):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            \n",
      "            bashcmdatlas = './cern-ldb -vs ' +  self.timbervarLumiAtlas + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnatlas + ' -F CSV'\n",
      "            bashcmdcms   = './cern-ldb -vs ' +  self.timbervarLumiCMS + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fncms + ' -F CSV'\n",
      "            bashcmdalice = './cern-ldb -vs ' +  self.timbervarLumiAlice + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnalice + ' -F CSV'\n",
      "            bashcmdlhcb  = './cern-ldb -vs ' +  self.timbervarLumiLHCB + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -N ' + fnlhcb + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdatlas,shell=True)\n",
      "                subprocess.call(bashcmdcms,shell=True)\n",
      "                subprocess.call(bashcmdalice,shell=True)\n",
      "                subprocess.call(bashcmdlhcb,shell=True)\n",
      "                \n",
      "                bashcmd1 = \"mv \" + fnatlas +  \".CSV \" + outfnatlas\n",
      "                bashcmd2 = \"mv \" + fncms   +  \".CSV \" + outfncms\n",
      "                bashcmd3 = \"mv \" + fnalice +  \".CSV \" + outfnalice\n",
      "                bashcmd4 = \"mv \" + fnlhcb  +  \".CSV \" + outfnlhcb\n",
      "                \n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                subprocess.call(bashcmd2,shell=True)\n",
      "                subprocess.call(bashcmd3,shell=True)\n",
      "                subprocess.call(bashcmd4,shell=True)\n",
      "                \n",
      "                fileexist = True\n",
      "            \n",
      "                atlaslumidata = pd.read_csv(outfnatlas,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                cmslumidata = pd.read_csv(outfncms,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                alicelumidata = pd.read_csv(outfnalice,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                lhcblumidata = pd.read_csv(outfnlhcb,delimiter=',',header=None,names=['t','L'],\n",
      "                                          skiprows=[0,1,2])\n",
      "                \n",
      "                atlaslumidata.to_csv(outfnatlas,index=None)\n",
      "                cmslumidata.to_csv(outfncms,index=None)\n",
      "                alicelumidata.to_csv(outfnalice,index=None)\n",
      "                lhcblumidata.to_csv(outfnlhcb,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            \n",
      "            atlaslumidata = pd.read_csv(outfnatlas)\n",
      "            cmslumidata = pd.read_csv(outfncms)\n",
      "            alicelumidata = pd.read_csv(outfnalice)\n",
      "            lhcblumidata = pd.read_csv(outfnlhcb)\n",
      "            return atlaslumidata,cmslumidata,alicelumidata,lhcblumidata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n",
      "    \n",
      "    def gethorbpm(self,fn):\n",
      "        tdc = self.gettimes()\n",
      "        fileexist = False\n",
      "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
      "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
      "            fileexist = True\n",
      "        else:\n",
      "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
      "            start = tdc[str(self.fillnumber)][-1][0]\n",
      "            bashcmdhorbpm = './cern-ldb -vs ' +  self.timbervarhorbpm + ' -t1 \\\"' + start +                            '\\\" -t2 \\\"' + stop + '\\\" -sa REPEAT -ss 5 -si MINUTE -N ' + fn + ' -F CSV'\n",
      "            try:\n",
      "                subprocess.call(bashcmdhorbpm,shell=True)\n",
      "                fileexist = True\n",
      "                bashcmd1 = \"mv \" + fn +  \".CSV \" + outfn\n",
      "                subprocess.call(bashcmd1,shell=True)\n",
      "                \n",
      "                bpmdata = pd.read_csv(outfn,delimiter=',',header=None,\n",
      "                                          skiprows=[0,1,2])\n",
      "                bpmdata.to_csv(outfn,index=None)\n",
      "            except:\n",
      "                print 'Loading of data failed.'\n",
      "        if fileexist:\n",
      "            df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
      "            colnames = list(df.columns[1:])\n",
      "            colnames[:0] =['t']\n",
      "            bpmdata = pd.read_csv(outfn,names=colnames)\n",
      "            return bpmdata\n",
      "        else:\n",
      "            print 'Something went wrong no data loaded.'\n",
      "            return 0\n"
     ]
    }
   ],
   "source": [
    "%save -f TimberGetDataClass.py 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CTE(object):\n",
    "    intensityout  = 'intensity.out'\n",
    "    emittanceout  = 'emittance.out'\n",
    "    ibsout        = 'ibs.out'\n",
    "    luminosityout = 'luminosity.out'\n",
    "    oldheaders = ['sim.turn', 't(hours)', \n",
    "               'N1_macro', 'N1_real', 'NlostLum1', 'Sum', \n",
    "               'NlostDebunch1','Sum.1', 'NLostBet1', 'Sum.2', 'NlostMom1', 'Sum.3', \n",
    "               'N2_macro', 'N2_real', 'NlostLum2','Sum.4', \n",
    "               'NlostDebunch2', 'SumNLostBet2', 'Sum.5', 'NlostMom2', 'Sum.6','']\n",
    "\n",
    "    oldlumiheader = ['sim.turn','t(hours)','L(cm^-2 s^-1)' ,'reduction factor','Beta']\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self.intensity, self.emit, self.ibs, self.lumi = self.loaddata()\n",
    "        self.macropartconv =  self.intensity['N1_real'].iloc[0]/self.intensity['N1_macro'].iloc[0]\n",
    "        \n",
    "    def loaddata(self):\n",
    "        intensfile    = self.path + '/' + self.intensityout\n",
    "        emitfile      = self.path + '/' + self.emittanceout\n",
    "        lumifile      = self.path + '/' + self.luminosityout\n",
    "        ibsfile       = self.path + '/' + self.ibsout\n",
    "        \n",
    "        intensitysimdata = pd.read_csv(intensfile,skiprows=[0,1],names=self.oldheaders,\n",
    "                                       delim_whitespace=True,index_col=None)\n",
    "        emittancesimdata = pd.read_csv(emitfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
    "        ibssimdata       = pd.read_csv(ibsfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
    "        lumisimdata      = pd.read_csv(lumifile,skiprows=[0,1],delim_whitespace=True,\n",
    "                                       names=self.oldlumiheader,index_col=None)\n",
    "        return intensitysimdata,emittancesimdata,ibssimdata,lumisimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following commands were written to file `CTEGetDataClass.py`:\n",
      "class CTE(object):\n",
      "    intensityout  = 'intensity.out'\n",
      "    emittanceout  = 'emittance.out'\n",
      "    ibsout        = 'ibs.out'\n",
      "    luminosityout = 'luminosity.out'\n",
      "    oldheaders = ['sim.turn', 't(hours)', \n",
      "               'N1_macro', 'N1_real', 'NlostLum1', 'Sum', \n",
      "               'NlostDebunch1','Sum.1', 'NLostBet1', 'Sum.2', 'NlostMom1', 'Sum.3', \n",
      "               'N2_macro', 'N2_real', 'NlostLum2','Sum.4', \n",
      "               'NlostDebunch2', 'SumNLostBet2', 'Sum.5', 'NlostMom2', 'Sum.6','']\n",
      "\n",
      "    oldlumiheader = ['sim.turn','t(hours)','L(cm^-2 s^-1)' ,'reduction factor','Beta']\n",
      "    \n",
      "    def __init__(self,path):\n",
      "        self.path = path\n",
      "        self.intensity, self.emit, self.ibs, self.lumi = self.loaddata()\n",
      "        self.macropartconv =  self.intensity['N1_real'].iloc[0]/self.intensity['N1_macro'].iloc[0]\n",
      "        \n",
      "    def loaddata(self):\n",
      "        intensfile    = self.path + '/' + self.intensityout\n",
      "        emitfile      = self.path + '/' + self.emittanceout\n",
      "        lumifile      = self.path + '/' + self.luminosityout\n",
      "        ibsfile       = self.path + '/' + self.ibsout\n",
      "        \n",
      "        intensitysimdata = pd.read_csv(intensfile,skiprows=[0,1],names=self.oldheaders,\n",
      "                                       delim_whitespace=True,index_col=None)\n",
      "        emittancesimdata = pd.read_csv(emitfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
      "        ibssimdata       = pd.read_csv(ibsfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
      "        lumisimdata      = pd.read_csv(lumifile,skiprows=[0,1],delim_whitespace=True,\n",
      "                                       names=self.oldlumiheader,index_col=None)\n",
      "        return intensitysimdata,emittancesimdata,ibssimdata,lumisimdata\n"
     ]
    }
   ],
   "source": [
    "%save -f CTEGetDataClass.py 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccte = CTE('/afs/cern.ch/work/t/tomerten/CTEJOBS/HI2016/Stableb4leveled/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccte.intensity.plot(x='t(hours)',y='N1_real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(fn1,'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    linenumber=1\n",
    "    try:\n",
    "        for row in reader:\n",
    "            linenumber +=1\n",
    "    except Exception as e:\n",
    "        print (('Error in line %d: %s %s  '% (linenumber,str(type(e)),e.message)))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
