{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyTimber_Tom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import glob\n",
    "import datetime\n",
    "import collections\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from scipy import optimize as opt\n",
    "from scipy import constants as const\n",
    "from StringIO import StringIO\n",
    "from matplotlib import rc,rcParams\n",
    "from matplotlib.patches import Rectangle\n",
    "import itertools\n",
    "from pandas import HDFStore \n",
    "\n",
    "# simdata\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from pandas.tools.plotting import lag_plot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# fucntion to get a list of fills in a user defined time interval\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def getfills(t1,t2):\n",
    "    bashcmd = './cern-ldb -vs ' + 'HX:FILLN' + ' -t1 \\\"' + t1 + '\\\" -t2 \\\"' +\\\n",
    "                            t2 + '\\\" -N ' + 'fn' + ' -F CSV'\n",
    "    subprocess.call(bashcmd,shell=True)\n",
    "    df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2])\n",
    "    subprocess.call('rm fn.CSV',shell=True)\n",
    "    return df\n",
    "\n",
    "class LHCfill(object):\n",
    "    # path to file with horizontal bpm names,etc\n",
    "    timbernames = '/afs/cern.ch/user/t/tomerten/public/timbernames.h5'\n",
    "    hdftimbernames = HDFStore(timbernames)\n",
    "    \n",
    "    # names of timberdata we want to extract\n",
    "    timbervarFBCTB1    = 'LHC.BCTFR.A6R4.B1:BUNCH_INTENSITY'\n",
    "    timbervarFBCTB2    = 'LHC.BCTFR.A6R4.B2:BUNCH_INTENSITY'\n",
    "\n",
    "    timbervarBQMB1L    = 'LHC.BQM.B1:BUNCH_LENGTHS'\n",
    "    timbervarBQMB1F    = 'LHC.BQM.B1:FILLED_BUCKETS'\n",
    "\n",
    "    timbervarBQMB2L    = 'LHC.BQM.B2:BUNCH_LENGTHS'\n",
    "    timbervarBQMB2F    = 'LHC.BQM.B2:FILLED_BUCKETS'\n",
    "\n",
    "    timbervarBSRTB1H   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_H'\n",
    "    timbervarBSRTB1V   = 'LHC.BSRT.5R4.B1:FIT_SIGMA_V'\n",
    "    timbervarBSRTB1GD  = 'LHC.BSRT.5R4.B1:GATE_DELAY'\n",
    "    timbervarBSRTB1CH  = 'LHC.BSRT.5R4.B1:LSF_H'\n",
    "    timbervarBSRTB1CV  = 'LHC.BSRT.5R4.B1:LSF_V'\n",
    "\n",
    "    timbervarBSRTB2H   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_H'\n",
    "    timbervarBSRTB2V   = 'LHC.BSRT.5L4.B2:FIT_SIGMA_V'\n",
    "    timbervarBSRTB2GD  = 'LHC.BSRT.5L4.B2:GATE_DELAY'\n",
    "    timbervarBSRTB2CH  = 'LHC.BSRT.5L4.B2:LSF_H'\n",
    "    timbervarBSRTB2CV  = 'LHC.BSRT.5L4.B2:LSF_V'\n",
    "\n",
    "    timbervarLumiAtlas = \"ATLAS:LUMI_TOT_INST\"\n",
    "    timbervarLumiAlice = \"ALICE:LUMI_TOT_INST\"\n",
    "    timbervarLumiCMS   = \"CMS:LUMI_TOT_INST\"\n",
    "    timbervarLumiLHCB  = \"LHCB:LUMI_TOT_INST\"\n",
    "    \n",
    "    timbervarhorbpm    = 'LHC.BOFSU:POSITIONS_H'\n",
    "    \n",
    "    fillkeys = ['/summary',\n",
    "                '/bpmhor/bpmdata',\n",
    "                '/bpmhor/bpmmask',\n",
    "                 '/bunchintensity/b1',\n",
    "                 '/bunchintensity/b1pos',\n",
    "                 '/bunchintensity/b2',\n",
    "                 '/bunchintensity/b2pos',\n",
    "                 '/bunchlenght/b1',\n",
    "                 '/bunchlenght/b1pos',\n",
    "                 '/bunchlenght/b2',\n",
    "                 '/bunchlenght/b2pos',\n",
    "                 '/emit/ex1',\n",
    "                 '/emit/ex2',\n",
    "                 '/emit/ey1',\n",
    "                 '/emit/ey2',\n",
    "                 '/lumi/alice',\n",
    "                 '/lumi/atlas',\n",
    "                 '/lumi/cms',\n",
    "                 '/lumi/lhcb']\n",
    "    # constants\n",
    "    protonmass = const.physical_constants['proton mass energy equivalent in MeV'][0]/1000 # GeV\n",
    "    ionA       = 208.\n",
    "    ionZ       = 82.\n",
    "    energy     = 6370\n",
    "    gamma      = energy * ionZ / 193.7291748489224\n",
    "\n",
    "    # beta's for the undulators and dipoles for the bsrt light\n",
    "    betaUndH = [203.,200.]\n",
    "    betaUndV = [318.,327.]\n",
    "    betaDipH = [214., 205.]\n",
    "    betaDipV = [328.,344.]\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    # initialization :\n",
    "    # ----------------\n",
    "    # fillnumber                : int\n",
    "    # basedir                   : string\n",
    "    # summarydf                 : pandas dataframe\n",
    "    # bunchlenb1df,bunchlenb1df : pandas dataframe\n",
    "    # ex1df,ey1df,ex2df,ey2df   : pandas dataframe\n",
    "    # I1df, I2df                : pandas dataframe\n",
    "    # lumiatlasdf,lumicmsdf,lumialicedf,lumilhcbdf : pandas dataframe\n",
    "    # bpmhdf                    : pandas dataframe\n",
    "    # bpmhmask                  : pandas dataframe\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def __init__(self,fillnumber,basedir):\n",
    "        # creating/opening hdf5 file for retreiving or appending data\n",
    "        fillfn         = basedir + str(fillnumnber) + '.h5'\n",
    "        hdffill        = HDFStore(fillfn)\n",
    "                \n",
    "        self.fillnumber = fillnumber\n",
    "        self.basedir    = basedir\n",
    "        \n",
    "        self.summary    = self.getsummary()\n",
    "        \n",
    "        self.bunchlenb1df, self.bunch2enb1df = self.getbunchlenghts('Fill' + str(self.fillnumber) + 'BLb1',\n",
    "                                                                    'Fill' + str(self.fillnumber) + 'BLb2')\n",
    "        \n",
    "        self.ex1df,self.ey1df,self.ex2df,self.ey2df = self.getemitbsrt('Fill' + str(self.fillnumber) +'emit1',\n",
    "                                                                       'Fill' + str(self.fillnumber)+'emit2') \n",
    "        \n",
    "        self.I1df,self.I2df                         = self.getFBCT('Fill' + str(self.fillnumber) +'fbct1',\n",
    "                                                                   'Fill' + str(self.fillnumber)+'fbct2')\n",
    "        \n",
    "        self.lumiatlasdf,self.lumicmsdf,self.lumialicedf,self.lumilhcbdf = self.getlumi('Fill' + \n",
    "                                                                                        str(self.fillnumber) +\n",
    "                                                                                        'atlas','Fill' + \n",
    "                                                                                        str(self.fillnumber)+\n",
    "                                                                                        'cms',\n",
    "                                                                                        'Fill' + \n",
    "                                                                                        str(self.fillnumber) +\n",
    "                                                                                        'alice','Fill' +\n",
    "                                                                                        str(self.fillnumber)+\n",
    "                                                                                        'lhcb')\n",
    "        self.bpmhdf    = self.gethorbpm('Fill' + str(self.fillnumber) +'bpmH')\n",
    "        self.bpmhmask  = self.gethorbpmmask('bpmhmask' + str(self.fillnumber))\n",
    "      \n",
    "    # -----------------------------------\n",
    "    # simplified timber download function\n",
    "    # -----------------------------------\n",
    "    def download(start,stop,timbervar,fn=None,fixed=None,cols=None):\n",
    "        bashcmd = './cern-ldb -vs ' + var + ' -t1 \\\"' + start + '\\\" -t2 \\\"' +\\\n",
    "                            stop + '\\\" -N ' + 'fn' + ' -F CSV'\n",
    "        try:\n",
    "            subprocess.call(bashcmd,shell=True)\n",
    "        except:\n",
    "            print 'Loading of data failed.'\n",
    "            \n",
    "        if fixed == None:  \n",
    "            if cols == None:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2])\n",
    "            else:\n",
    "                 df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],usecols=cols)\n",
    "        else:\n",
    "            if cols == None:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],names=fixed)\n",
    "            else:\n",
    "                df = pd.read_csv('fn.CSV',delimiter=',',header=None,skiprows=[0,1,2],names=fixed,usecols=cols)\n",
    "        \n",
    "        if fn == None:\n",
    "            subprocess.call('rm fn.CSV',shell=True)\n",
    "            return df\n",
    "        else:\n",
    "            if type(fn)== str:\n",
    "                subprocess.call('mv fn.CSV ' + fn ,shell=True)\n",
    "                return fn\n",
    "            else:\n",
    "                print 'invalid filename'\n",
    "                return 0\n",
    "    \n",
    "    # --------------------\n",
    "    # returns fill summary\n",
    "    # --------------------\n",
    "    def getsummary(self):\n",
    "        # check if already present in hdf file\n",
    "        if '/summary' in hdffill.keys():\n",
    "            dfsummary = hdffill['/summary']\n",
    "        else:\n",
    "            infn   = \"Fill\" + str(self.fillnumber) + \"Summary\"\n",
    "            bashcmd1 = \"./cern-ldb -M FD -fn \" + str(self.fillnumber) + \" -N  \" + infn + \" -F CSV\"\n",
    "            bashcmd2 = \"rm \" + infn + \".CSV \"\n",
    "            subprocess.call(bashcmd1,shell=True)\n",
    "            subprocess.call(bashcmd2,shell=True)\n",
    "            dfsummary = pd.read_csv(infn + \".CSV\",delimiter=',',header=0)\n",
    "            hdffill.put('summary',dfsummary,format='table')\n",
    "        return dfsummary\n",
    "    \n",
    "    # -------------------------\n",
    "    # def convert to unix time\n",
    "    # -------------------------\n",
    "    def converttimetounix(self,t):\n",
    "        return time.mktime(datetime.datetime.strptime(t,\"%Y-%m-%d %H:%M:%S.%f\").timetuple())\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # function for adding times in YY-mm-dd HH:MM:SS.fff format\n",
    "    # ---------------------------------------------------------\n",
    "    def addtime(self,intime,deltahour):\n",
    "        mytime = datetime.datetime.strptime(intime,\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        mytime += datetime.timedelta(hours=deltahour)\n",
    "        return mytime.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # returns dict with start stop times of modes in a fill\n",
    "    # ---------------------------------------------------------\n",
    "    def gettimes(self):\n",
    "        timesodic = collections.OrderedDict()\n",
    "        if '/summary' in hdffill.keys():\n",
    "            dfsummary = hdffill['/summary']\n",
    "            dc = collections.OrderedDict()\n",
    "            for name, group in dfsummary.groupby('Value'):\n",
    "                starttimes = group['StartTime(UTC_TIME)'].values\n",
    "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
    "                arr = np.array([starttimes,stoptimes])\n",
    "                dc[name] = np.transpose(arr)\n",
    "            return dc\n",
    "        else:\n",
    "            dfsummary = self.getsummary()\n",
    "            dc = collections.OrderedDict()\n",
    "            for name, group in dfsummary.groupby('Value'):\n",
    "                starttimes = group['StartTime(UTC_TIME)'].values\n",
    "                stoptimes  = group['EndTime(UTC_TIME)'].values\n",
    "                arr = np.array([starttimes,stoptimes])\n",
    "                dc[name] = np.transpose(arr)\n",
    "            return dc\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # returns arrays with the bunch slots\n",
    "    # ---------------------------------------------------------\n",
    "    def getbunchpositions(self):\n",
    "        # get beginning and end of fill\n",
    "        tdc = self.gettimes()\n",
    "        # check if data already present\n",
    "        if (('/bunchlenght/b1pos' in hdffill.keys()) & ('/bunchlenght/b2pos' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchpos = hfdfill['/bunchlenght/b1pos']\n",
    "                b2bunchpos = hdffill['/bunchlenght/b2pos']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "        else:\n",
    "            # if data not present download and transform in dataframe + store \n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            b1bunchpos = self.download(start,stop,self.timbervarBQMB1F)\n",
    "            b2bunchpos = self.download(start,stop,self.timbervarBQMB2F)\n",
    "            \n",
    "            # write to hdf \n",
    "            hdffill.put('/bunchlenght/b1pos',b1bunchpos.astype(int))\n",
    "            hdffill.put('/bunchlenght/b2pos',b2bunchpos.astype(int))\n",
    "\n",
    "        \n",
    "        return [int((i-1.)/10.) for i in b1bunchpos.drop(0,axis=1)[b1bunchpos.drop(0,axis=1).sum(axis=1).values>0].tail(1).values[0] if i >0],\\\n",
    "            [int((i-1.)/10.) for i in b2bunchpos.drop(0,axis=1)[b2bunchpos.drop(0,axis=1).sum(axis=1).values>0].tail(1).values[0] if i >0]\n",
    "       \n",
    "    # ---------------------------------------------------------\n",
    "    # returns the bunch lengths \n",
    "    # ---------------------------------------------------------\n",
    "    def getbunchlenghts(self):\n",
    "        tdc = self.gettimes()\n",
    "        # check if data already present\n",
    "        if (('/bunchlenght/b1' in hdffill.keys()) & ('/bunchlenght/b2' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchdata = hfdfill['/bunchlenght/b1']\n",
    "                b2bunchdata = hdffill['/bunchlenght/b2']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            b1bunchdata = self.download(start,stop,self.timbervarBQMB1L)\n",
    "            b2bunchdata = self.download(start,stop,self.timbervarBQMB2L)\n",
    " \n",
    "            bposb1, bposb2 = self.getbunchpositions()\n",
    "            bposb1[:0]=[0]\n",
    "            bposb2[:0]=[0]\n",
    "        return b1bunchdata[bposb1],b2bunchdata[bposb2]\n",
    "        \n",
    "    \n",
    "    def convertdicttodf(self,dictin):\n",
    "        dflist        = [pd.DataFrame(np.array(dictin[i]),columns=[0,i]) for i in dictin.keys()]\n",
    "        dflistgrouped = [dflist[i].groupby(0,as_index=False).mean() for i in range(len(dflist))]\n",
    "        dffinal       = reduce(lambda left,right: pd.merge(left,right,on=0,how='outer'),dflistgrouped)\n",
    "        dffinal2      = dffinal.fillna(0)\n",
    "        cols          = dffinal.columns\n",
    "        return dffinal2.loc[(dffinal2[cols[1:]]!=0).any(1)]\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # getting bsrt data\n",
    "    # ---------------------------------------------------------\n",
    "    def getemitbsrt(self):\n",
    "        if (('/emit/ex1' in hdffill.keys()) & \n",
    "            ('/emit/ey1' in hdffill.keys()) &\n",
    "            ('/emit/ex2' in hdffill.keys()) & \n",
    "            ('/emit/ey2' in hdffill.keys())):\n",
    "            ex1dfout = hdffill['/emit/ex1']\n",
    "            ey1dfout = hdffill['/emit/ey1']\n",
    "            ex2dfout = hdffill['/emit/ex2']\n",
    "            ey2dfout = hdffill['/emit/ey2']\n",
    "        else:\n",
    "            tdc = self.gettimes()\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            try:\n",
    "                # downloading the files\n",
    "                # +++++++++++++++++++++\n",
    "                \n",
    "                fgdb1   = self.download(start,stop,self.timbervarBSRTB1GD,fixed=range(200))\n",
    "                fsighb1 = self.download(start,stop,self.timbervarBSRTB1H,fixed=range(200))\n",
    "                fsigvb1 = self.download(start,stop,self.timbervarBSRTB1V,fixed=range(200))\n",
    "\n",
    "                fgdb1   = self.download(start,stop,self.timbervarBSRTB2G,fixed=range(200))\n",
    "                fsighb1 = self.download(start,stop,self.timbervarBSRTB2H,fixed=range(200))\n",
    "                fsigvb1 = self.download(start,stop,self.timbervarBSRTB2V,fixed=range(200))\n",
    "\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "                \n",
    "            # transforming sigma to emit\n",
    "            # ++++++++++++++++++++++++++\n",
    "            fgdb1conv  = fgdb1.fillna(value=0).astype(int)\n",
    "            bunchesb1  = fgdb1conv.drop(0,axis=1).as_matrix()\n",
    "            bunchsetb1 = set(bunches.flatten())\n",
    "            dfex1b1       = pd.DataFrame()\n",
    "            dfey1b1       = pd.DataFrame()\n",
    "            \n",
    "            for b in bunchsetb1:\n",
    "                bunchmask   = (fgdb1conv==b)\n",
    "                hor         = fsighb1.where(bunchmask)\n",
    "                ver         = fsigvb1.where(bunchmask)\n",
    "                hortempdf      = pd.DataFrame()\n",
    "                hortempdf['t'] = pd.Series(fsighb1.iloc[hor.mean().dropna().index][0])\n",
    "                hortempdf[b]   = hor.mean().dropna()\n",
    "                vertempdf      = pd.DataFrame()\n",
    "                vertempdf['t'] = pd.Series(fsigvb1.iloc[ver.mean().dropna().index][0])\n",
    "                vertempdf[b]   = ver.mean().dropna()\n",
    "                dfex1b1        = dfex1b1.append(hortempdf)\n",
    "                dfey1b1        = dfey1b1.append(vertempdf)\n",
    "                \n",
    "            fgdb2conv  = fgdb2.fillna(value=0).astype(int)\n",
    "            bunchesb2  = fgdb2conv.drop(0,axis=1).as_matrix()\n",
    "            bunchsetb2 = set(bunches.flatten())\n",
    "            dfex2b2       = pd.DataFrame()\n",
    "            dfey2b2       = pd.DataFrame()\n",
    "            \n",
    "            for b in bunchsetb2:\n",
    "                bunchmask   = (fgdb2conv==b)\n",
    "                hor         = fsighb2.where(bunchmask)\n",
    "                ver         = fsigvb2.where(bunchmask)\n",
    "                hortempdf      = pd.DataFrame()\n",
    "                hortempdf['t'] = pd.Series(fsighb2.iloc[hor.mean().dropna().index][0])\n",
    "                hortempdf[b]   = hor.mean().dropna()\n",
    "                vertempdf      = pd.DataFrame()\n",
    "                vertempdf['t'] = pd.Series(fsigvb2.iloc[ver.mean().dropna().index][0])\n",
    "                vertempdf[b]   = ver.mean().dropna()\n",
    "                dfex2b2        = dfex2b2.append(hortempdf)\n",
    "                dfey2b2        = dfey2b2.append(vertempdf)\n",
    "  \n",
    "            # get end of ramp for switching betas\n",
    "            # +++++++++++++++++++++++++++++++++++\n",
    "            rampend = tdc['RAMP'][-1][-1]\n",
    "            rampend = self.converttimetounix(rampend)\n",
    "\n",
    "            dfex1b1set = dfex1b1.set_index('t')\n",
    "            dfey1b1set = dfey1b1.set_index('t')\n",
    "            dfex2b2set = dfex1b1.set_index('t')\n",
    "            dfey2b2set = dfex1b1.set_index('t')\n",
    "            \n",
    "            \n",
    "            dfex1b1set[dfex1b1set.index>rampend] = \\\n",
    "                dfex1b1set[dfex1b1set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipH[0])\n",
    "            dfex1b1set[dfex1b1set.index<=rampend] = \\\n",
    "                dfex1b1set[dfex1b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndH[0])\n",
    "            dfey1b1set[dfey1b1set.index>rampend] = \\\n",
    "                dfey1b1set[dfey1b1set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipV[1])\n",
    "            dfey1b1set[dfey1b1set.index<=rampend] = \\\n",
    "                dfey1b1set[dfey1b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndV[1])\n",
    "                \n",
    "            dfex2b2set[dfex2b2set.index>rampend] = \\\n",
    "                dfex2b2set[dfex2b2set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipH[0])\n",
    "            dfex2b2set[dfex2b2set.index<=rampend] = \\\n",
    "                dfex2b2set[d2ex2b1set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndH[0])\n",
    "            dfey2b2set[dfey2b2set.index>rampend] = \\\n",
    "                dfey2b2set[dfey2b2set.index>rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaDipV[1])\n",
    "            dfey2b2set[dfey2b2set.index<=rampend] = \\\n",
    "                dfey2b2set[dfey2b2set.index<=rampend].applymap(lambda x: \n",
    "                                                              self.gamma * float(x)**2/self.betaUndV[1])\n",
    "                \n",
    "            # writing to disc and return result\n",
    "            # +++++++++++++++++++++++++++++++++++  \n",
    "            ex1dfout = dfex1b1set.reset_index()\n",
    "            ey1dfout = dfey1b1set.reset_index()\n",
    "            ex2dfout = dfex2b2set.reset_index()\n",
    "            ey2dfout = dfey2b2set.reset_index()\n",
    "            hdffill['/emit/ex1'] = ex1dfout\n",
    "            hdffill['/emit/ey1'] = ey1dfout\n",
    "            hdffill['/emit/ex2'] = ex2dfout\n",
    "            hdffill['/emit/ey2'] = ey2dfout\n",
    "            \n",
    "                \n",
    "        return ex1dfout,ey1dfout,ex2dfout,ey2dfout\n",
    "     \n",
    "    # ---------------------------------------------------------\n",
    "    # getting FBCT data\n",
    "    # ---------------------------------------------------------\n",
    "    def getFBCT(self):\n",
    "        tdc = self.gettimes()\n",
    "    \n",
    "        cols1,cols2 = self.getbunchpositions()\n",
    "        cols1 = [i + 1 for i in cols1]\n",
    "        cols2 = [i + 1 for i in cols2]\n",
    "        cols1[:0] = [0]\n",
    "        cols2[:0] = [0]\n",
    "        \n",
    "        # if data exist reload\n",
    "        # ++++++++++++++++++++\n",
    "        if (('/bunchintensity/b1' in hdffill.keys()) & ('/bunchintensity/b2' in hdffill.keys())):\n",
    "            try:\n",
    "                b1bunchdata = hfdfill['/bunchintensity/b1']\n",
    "                b2bunchdata = hdffill['/bunchintensity/b2']\n",
    "            except:\n",
    "                print 'Something went wrong, no data loaded.'\n",
    "                \n",
    "        # if data not present download\n",
    "        # ++++++++++++++++++++++++++++\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            try:\n",
    "                b1bunchdata = self.download(start,stop,self.timbervarFBCTB1,fixed=range(3565),cols=cols1)\n",
    "                b2bunchdata = self.download(start,stop,self.timbervarFBCTB2,fixed=range(3565),cols=cols2)\n",
    "                b1bunchdata.columns = [i-1 if i !=0 else 0 for i in cols1]\n",
    "                b2bunchdata.columns = [i-1 if i !=0 else 0 for i in cols2]\n",
    "                b1bunchdata.to_csv(outfn1,index=None)\n",
    "                b2bunchdata.to_csv(outfn2,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "                \n",
    "            hfdfill['/bunchintensity/b1'] = b1bunchdata\n",
    "            hdffill['/bunchintensity/b2'] = b2bunchdata\n",
    "            \n",
    "        return b1bunchdata,b2bunchdata\n",
    "       \n",
    "    # ---------------------------------------------------------\n",
    "    # getting lumi data\n",
    "    # ---------------------------------------------------------\n",
    "    def getlumi(self):\n",
    "        tdc = self.gettimes()\n",
    "           \n",
    "        if (('/lumi/alice' in hdffill.keys()) &\n",
    "            ('/lumi/atlas' in hdffill.keys()) &\n",
    "            ('/lumi/cms' in hdffill.keys()) &\n",
    "            ('/lumi/lhcb' in hdffill.keys())):\n",
    "            atlaslumidata = hfdfill['/lumi/alice']\n",
    "            cmslumidata   = hfdfill['/lumi/atlas']\n",
    "            alicelumidata = hfdfill['/lumi/cms']\n",
    "            lhcblumidata  = hfdfill['/lumi/lhcb']\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            \n",
    "            atlaslumidata = self.download(start,stop,self.timbervarLumiAtlas)\n",
    "            cmslumidata   = self.download(start,stop,self.timbervarLumiCMS)\n",
    "            alicelumidata = self.download(start,stop,self.timbervarLumiAlice)\n",
    "            lhcblumidata  = self.download(start,stop,self.timbervarLumiLHCB)\n",
    "            \n",
    "            atlaslumidata.columns = ['t','L']\n",
    "            cmslumidata.columns   = ['t','L']\n",
    "            alicelumidata.columns = ['t','L']\n",
    "            lhcblumidata.columns  = ['t','L']\n",
    "                   \n",
    "        return atlaslumidata,cmslumidata,alicelumidata,lhcblumidata\n",
    "    \n",
    "    def gethorbpm(self,fn):\n",
    "        tdc = self.gettimes()\n",
    "        fileexist = False\n",
    "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
    "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
    "            fileexist = True\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            bashcmdhorbpm = './cern-ldb -vs ' +  self.timbervarhorbpm + ' -t1 \\\"' + start +\\\n",
    "                            '\\\" -t2 \\\"' + stop + '\\\" -sa REPEAT -ss 5 -si MINUTE -N ' + fn + ' -F CSV'\n",
    "            try:\n",
    "                subprocess.call(bashcmdhorbpm,shell=True)\n",
    "                fileexist = True\n",
    "                bashcmd1 = \"mv \" + fn +  \".CSV \" + outfn\n",
    "                subprocess.call(bashcmd1,shell=True)\n",
    "                \n",
    "                bpmdata = pd.read_csv(outfn,delimiter=',',header=None,\n",
    "                                          skiprows=[0,1,2])\n",
    "                bpmdata.to_csv(outfn,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "        if fileexist:\n",
    "            df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
    "            colnames = list(df.columns[1:])\n",
    "            colnames[:0] =['t']\n",
    "            bpmdata = pd.read_csv(outfn,names=colnames,skiprows=[0])\n",
    "            return bpmdata\n",
    "        else:\n",
    "            print 'Something went wrong no data loaded.'\n",
    "            return 0\n",
    "        \n",
    "    def gethorbpmmask(self,fn):\n",
    "        tdc = self.gettimes()\n",
    "        fileexist = False\n",
    "        outfn  = self.basedir + \"/\" + fn + \".CSV\"\n",
    "        if os.path.isfile(self.basedir + '/' + fn + '.CSV'):\n",
    "            fileexist = True\n",
    "        else:\n",
    "            stop  = tdc[str(self.fillnumber)][-1][1]\n",
    "            start = tdc[str(self.fillnumber)][-1][0]\n",
    "            bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_MASK_H' + ' -t1 \\\"' + start +\\\n",
    "                            '\\\" -t2 \\\"'  + stop + '\\\" -N ' + 'bpmhmask' + str(self.fillnumber) + ' -F CSV'\n",
    "            try:\n",
    "                subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "                fileexist = True\n",
    "                bashcmd1 = \"mv \" + 'bpmhmask'+ str(self.fillnumber) + \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhmask'+ str(self.fillnumber) + '.csv'\n",
    "                subprocess.call(bashcmd1,shell=True)\n",
    "                dfmask = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
    "                dfmask.to_csv(outfn,index=None)\n",
    "            except:\n",
    "                print 'Loading of data failed.'\n",
    "        if fileexist:\n",
    "            df = pd.read_csv(outfn,skiprows=[0,1,2])\n",
    "            bpmdata = pd.read_csv(outfn,skiprows=[0,1,2],header=None)\n",
    "            return bpmdata\n",
    "        else:\n",
    "            print 'Something went wrong no data loaded.'\n",
    "            return 0\n",
    "        \n",
    "    def getbpmhreduced(self):\n",
    "        dfmask = self.bpmhmask\n",
    "\n",
    "        # selecting the last non-zero row of the maskfile to use as a mask on the bpm data\n",
    "        # not the best way but does the job for the moment\n",
    "        # problem to unequal shape of mask and data dataframes\n",
    "        dfcopy = pd.DataFrame(dfmask[range(1,1089)][dfmask[range(1,1089)].sum(axis=1).values>1.].tail(1).values, \n",
    "                              columns =  self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1).columns)\n",
    "\n",
    "        # taking the bpm data but removing the timestamps in order to be able to apply a mask\n",
    "        dffff = self.bpmhdf.drop(self.bpmhdf.columns[0],axis=1)\n",
    "        selection = dffff * dfcopy.iloc[0]\n",
    "        selectionred= selection[(selection>1.0)| (selection< -1.0)].dropna(axis=1,how='all')\n",
    "        return selectionred\n",
    "    \n",
    "    def transformbpmdata(self,tfslhcb1,tfslhcb2,ipnr=5):\n",
    "        selectionred = self.getbpmhreduced()\n",
    "        # selecting the BPM around the desired ip (pandas dataframes)\n",
    "        bpmrtest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R' + str(ipnr)\n",
    "                                                                                                   + '.B1')])]\n",
    "        bpmltest = selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L' + str(ipnr)\n",
    "                                                                                                   + '.B2')])]\n",
    "        # adding the s positions of these BPMs for plotting\n",
    "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
    "        colsb1 = list(tfsb1.columns[1:])\n",
    "\n",
    "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "\n",
    "        tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R' + str(ipnr) + '.B1'))]\n",
    "        tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "        tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "\n",
    "        namesr = list(bpmrtest.columns)\n",
    "\n",
    "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb2 = tfsb2[tfsb2['NAME']!='%s']\n",
    "        colsb2 = list(tfsb2.columns[1:])\n",
    "        tfsb2 = pd.read_csv(tfslhcb2,skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
    "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
    "        tfsbpml = tfsb2[(tfsb2['NAME'].str.contains('BPM')) & (tfsb2['NAME'].str.contains('L' + str(ipnr) + '.B2'))]\n",
    "        tfsbpml = tfsbpml[1:]\n",
    "        tfsbpml = tfsbpml[['NAME','S']]\n",
    "\n",
    "        namesl = list(bpmltest.columns)\n",
    "\n",
    "        return bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr\n",
    "    \n",
    "    def plotbpm(self,tfslhcb1,tfslhcb2,ipnr=5,nn=50,step=20,xmin=0,xmax=600):\n",
    "        bpmltest,namesl,tfsbpml,bpmrtest,namesr,tfsbpmr = self.transformbpmdata(\n",
    "                                                    tfslhcb1,\n",
    "                                                    tfslhcb2,\n",
    "                                                    ipnr=ipnr\n",
    "                                                   )\n",
    "        from IPython.html.widgets import FloatProgress\n",
    "        from IPython.display import display\n",
    "        f = FloatProgress(min=0,max=2*nn/float(step))\n",
    "        display(f)\n",
    "\n",
    "        error = False\n",
    "\n",
    "        tfsb1  = pd.read_csv(tfslhcb1,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb1  = tfsb1[tfsb1['NAME']!='%s']\n",
    "        colsb1 = list(tfsb1.columns[1:])\n",
    "\n",
    "        tfsb1 = pd.read_csv(tfslhcb1,skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "        tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "        sipb1 = tfsb1[tfsb1['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
    "\n",
    "        tfsb2  = pd.read_csv(tfslhcb2,skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "        tfsb2  = tfsb2[tfsb2['NAME']!='%s']\n",
    "        colsb2 = list(tfsb2.columns[1:])\n",
    "\n",
    "        tfsb2 = pd.read_csv(tfslhcb2, skiprows=range(46),delim_whitespace=True,names=colsb2,index_col=False)\n",
    "        tfsb2 = tfsb2[tfsb2['S']!='%s']\n",
    "        sipb2 = tfsb2[tfsb2['NAME']== 'IP'+ str(ipnr)]['S'].values[0]\n",
    "\n",
    "        tfsbpmr['S'] = tfsbpmr['S'].apply(lambda x: float(x)-float(sipb1))\n",
    "        tfsbpml['S'] = tfsbpml['S'].apply(lambda x: float(x)-float(sipb2))\n",
    "\n",
    "    #     print tfsbpmr\n",
    "\n",
    "        fig = plt.figure(figsize=(18,20))\n",
    "        ax  = fig.add_subplot(211)\n",
    "\n",
    "        s1   = np.array([float(tfsbpml[tfsbpml['NAME']==n]['S'].values[0]) for n in namesl])\n",
    "        max1 = len(bpmltest)\n",
    "\n",
    "\n",
    "        for i in range(0,len(bpmltest.tail(nn)),step):\n",
    "            try:\n",
    "                data = np.array([bpmltest[n][max1-nn+i] for n in namesl])\n",
    "                plt.scatter(s1,data)\n",
    "                plt.plot(s1,data)\n",
    "                f.value = i\n",
    "            except:\n",
    "                print 'nn out of range'\n",
    "                error = True\n",
    "                break\n",
    "\n",
    "\n",
    "    #     plt.plot((0,500),(500,500),'k-')\n",
    "    #     plt.plot((0,500),(-500,-500),'k-')\n",
    "    #     plt.plot((0,500),(-3000,-3000),'k-')\n",
    "    #     plt.plot((0,500),(-3500,-3500),'k-')\n",
    "    #     plt.plot((0,500),(0,0),'k-')\n",
    "        plt.grid()\n",
    "        plt.xlim(xmin,xmax)\n",
    "        plt.ylim(-5000,5000)\n",
    "\n",
    "        ax.set_xticks(np.arange(xmin,xmax,100))\n",
    "        ax.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
    "        ax.set_yticks(np.arange(-5000,5000,2000))\n",
    "        ax.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
    "        ax.grid(which='minor',alpha=0.65)\n",
    "\n",
    "        plt.xlabel('s',fontsize=16.0)\n",
    "        plt.ylabel('x [um]')\n",
    "        plt.title('BPM orbits Horizontal left of ' + str(ipnr) + ' - fill ' + str(LHCfill.fillnumber))\n",
    "\n",
    "    #     ax.text(100,4000, 'Each line (colour) is at a different timestamp.')\n",
    "\n",
    "    #     ax.annotate('roughly 0.5 mm below \\n 3mm from bump',xy=(440,-3400),xytext=(400,-5000),\n",
    "    #                 arrowprops=dict(facecolor='red',shrink=0.5))\n",
    "\n",
    "    #     ax.plot([440],[500],'o')\n",
    "\n",
    "    #     ax.annotate('Expected with 0.5 mm bump',xy=(440,500),xytext=(400,2500),\n",
    "    #                 arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "        ax2  = fig.add_subplot(2,1,2)\n",
    "        max2 = len(bpmrtest)\n",
    "        s2   = np.array([float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]) for n in namesr])\n",
    "\n",
    "        for i in range(0,len(bpmrtest.tail(nn)),step):\n",
    "            try:\n",
    "                data =  np.array([bpmrtest[n][max2-nn+i] for n in namesr])\n",
    "                ax2.scatter(s2,data)\n",
    "                ax2.plot(s2,data)\n",
    "                f.value = f.value +1 \n",
    "            except:\n",
    "                print 'nn out of range'\n",
    "                error = True\n",
    "                break\n",
    "        if error:\n",
    "            print 'No valid plot generated'\n",
    "        else:\n",
    "    #         plt.plot((0,500),(500,500),'k-')\n",
    "    #         plt.plot((0,500),(-500,-500),'k-')\n",
    "    #         plt.plot((0,500),(-3000,-3000),'k-')\n",
    "    #         plt.plot((0,500),(-3500,-3500),'k-')\n",
    "    #         plt.plot((0,500),(0,0),'k-')\n",
    "            plt.grid()\n",
    "            plt.xlim(xmin,xmax)\n",
    "            plt.ylim(-5000,5000)\n",
    "\n",
    "            ax2.set_xticks(np.arange(xmin,xmax,100))\n",
    "            ax2.set_xticks(np.arange(xmin,xmax,10),minor=True)\n",
    "            ax2.set_yticks(np.arange(-5000,5000,2000))\n",
    "            ax2.set_yticks(np.arange(-5000,5000,500),minor=True)\n",
    "\n",
    "            ax2.grid(which='minor',alpha=0.65)\n",
    "    #         ax2.annotate('roughly 0.5 mm above \\n 3mm from bump',xy=(433,-2650),xytext=(400,-5000),\n",
    "    #                     arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "            plt.xlabel('s',fontsize=16.0)\n",
    "            plt.ylabel('x [um]')\n",
    "            plt.title('BPM orbits Horizontal right of ' + str(ipnr) + '  - fill ' + str(LHCfill.fillnumber) )\n",
    "\n",
    "            plt.show()\n",
    "            print f.value\n",
    "            # plt.savefig('Fill4707IP5bpm.png',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%save -f LHCclass.py 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the names of the BPM's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_NAMES_H' + ' -t1 \\\"' + '2015-12-06 00:52:09.555' +\\\n",
    "#                             '\\\" -t2 \\\"' + '2015-12-06 12:39:41.084' + '\\\" -N ' + 'bpmnames' + ' -F CSV'\n",
    "# subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "# bashcmd1 = \"mv \" + 'bpmnames' +  \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv'\n",
    "# subprocess.call(bashcmd1,shell=True)\n",
    "df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2])\n",
    "df.columns[1:]\n",
    "colnames = list(df.columns[1:])\n",
    "colnames[:0] =['t']\n",
    "print len(colnames)\n",
    "df = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/bpmhnames.csv',skiprows=[0,1,2],names=colnames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fill =  LHCfill(4707,'/afs/cern.ch/work/t/tomerten/HI2015')\n",
    "fill4696 =  LHCfill(4696,'/afs/cern.ch/work/t/tomerten/HI2015')\n",
    "fill.summarydf\n",
    "fill.bpmdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globals()['rcParams']['font.size']=16.0\n",
    "globals()['rcParams']['xtick.major.size']=12.0\n",
    "globals()['rcParams']['ytick.major.size']=12.0\n",
    "globals()['rcParams']['axes.labelsize']=12.0\n",
    "globals()['rcParams']['xtick.labelsize']=12.0\n",
    "globals()['rcParams']['ytick.labelsize']=12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look up the times for downloading the mask\n",
    "fill4696.summarydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masktest = fill.gethorbpmmask('bpmhmask4696')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downloading the mask\n",
    "bashcmdhorbpmnames = './cern-ldb -vs ' +  'LHC.BOFSU:BPM_MASK_H' + ' -t1 \\\"' + '2015-12-06 00:52:09.555' +\\\n",
    "                            '\\\" -t2 \\\"' + '2015-12-06 12:39:41.084' + '\\\" -N ' + 'bpmmask4696' + ' -F CSV'\n",
    "subprocess.call(bashcmdhorbpmnames,shell=True)\n",
    "bashcmd1 = \"mv \" + 'bpmmask4696' +  \".CSV \" + '/afs/cern.ch/work/t/tomerten/HI2015/bpmhmask4696.csv'\n",
    "subprocess.call(bashcmd1,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "# ---------------------\n",
    "\n",
    "selectionred = fill4696.getbpmhreduced()\n",
    "# selecting bpm right and left of ip5\n",
    "bpmr5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R5.B1')])]\n",
    "bpml5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L5.B2')])]\n",
    "\n",
    "\n",
    "tfsb1 =pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfsb1 = tfsb1[tfsb1['NAME']!='%s']\n",
    "colsb1 = list(tfsb1.columns[1:])\n",
    "tfsb1 = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R5.B1'))]\n",
    "tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "namesr = list(bpmr5test.columns)\n",
    "\n",
    "# [[float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]),bpmr5test[n][0]] for n in namesr]\n",
    "# (fill4696.bpmdf['t'].tail(50)-fill4696.bpmdf['t'].head(1).values)/3600000\n",
    "bpmr5test.tail(50)\n",
    "\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfs = tfs[tfs['NAME']!='%s']\n",
    "cols = list(tfs.columns[1:])\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(46),delim_whitespace=True,names=cols,index_col=False)\n",
    "tfs = tfs[tfs['S']!='%s']\n",
    "tfsbpm= tfs[(tfs['NAME'].str.contains('BPM')) & (tfs['NAME'].str.contains('L5.B2'))]\n",
    "tfsbpm = tfsbpm[1:]\n",
    "tfsbpm = tfsbpm[['NAME','S']]\n",
    "names = list(bpml5test.columns)\n",
    "\n",
    "# bpml5test.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  transforming the data\n",
    "# ---------------------\n",
    "selectionred = fill.getbpmhreduced()\n",
    "\n",
    "# selecting bpm right and left of ip5\n",
    "bpmr5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('R5.B1')])]\n",
    "bpml5test =selectionred[(selectionred.columns[selectionred.columns.to_series().str.contains('L5.B2')])]\n",
    "\n",
    "\n",
    "tfsb1 =pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfsb1 = tfsb1[tfsb1['NAME']!='%s']\n",
    "colsb1 = list(tfsb1.columns[1:])\n",
    "tfsb1 = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/LHCTwiss-LHCB1.tfs',skiprows=range(46),delim_whitespace=True,names=colsb1,index_col=False)\n",
    "tfsb1 = tfsb1[tfsb1['S']!='%s']\n",
    "tfsbpmr= tfsb1[(tfsb1['NAME'].str.contains('BPM')) & (tfsb1['NAME'].str.contains('R5.B1'))]\n",
    "tfsbpmr = tfsbpmr[tfsbpmr['NAME']!='BPMSW.1R5.B1_DOROS']\n",
    "tfsbpmr = tfsbpmr[['NAME','S']]\n",
    "namesr = list(bpmr5test.columns)\n",
    "\n",
    "# [[float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]),bpmr5test[n][0]] for n in namesr]\n",
    "# (fill4696.bpmdf['t'].tail(50)-fill4696.bpmdf['t'].head(1).values)/3600000\n",
    "bpmr5test.tail(50)\n",
    "\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(45),nrows=2,delim_whitespace=True)\n",
    "tfs = tfs[tfs['NAME']!='%s']\n",
    "cols = list(tfs.columns[1:])\n",
    "tfs = pd.read_csv('/afs/cern.ch/work/t/tomerten/HI2015/lhcb2-twiss-noerr.tfs',skiprows=range(46),delim_whitespace=True,names=cols,index_col=False)\n",
    "tfs = tfs[tfs['S']!='%s']\n",
    "tfsbpm= tfs[(tfs['NAME'].str.contains('BPM')) & (tfs['NAME'].str.contains('L5.B2'))]\n",
    "tfsbpm = tfsbpm[1:]\n",
    "tfsbpm = tfsbpm[['NAME','S']]\n",
    "names = list(bpml5test.columns)\n",
    "\n",
    "print bpml5test.columns, bpmr5test.columns\n",
    "# (fill.bpmdf['t'].tail(100)-fill.bpmdf['t'].head(2).values[1])/3600000\n",
    "# dfmask[range(1,1089)][dfmask[range(1,1089)].sum(axis=1).values>1.].tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcopy = pd.DataFrame(fill.bpmhmask[range(1,1089)][fill.bpmhmask[range(1,1089)].sum(axis=1).values>1.].tail(1).values, \n",
    "                              columns =  fill.bpmdf.drop(fill.bpmdf.columns[0],axis=1).columns)\n",
    "dfcopy['BPM.11R5.B1']\n",
    "dfcopy.iloc[0]['BPM.11R5.B1']\n",
    "dffff = fill.bpmdf.drop(fill.bpmdf.columns[0],axis=1)\n",
    "ss = dffff.multiply(dfcopy.iloc[0],axis=1)\n",
    "ss = dffff[(dffff>1.0)| (dffff< -1.0)]#.dropna(axis=1)\n",
    "# ss.dropna(axis=1,how='all')\n",
    "# ['BPM.11R5.B1']\n",
    "# dffff['BPMWF.A1R1.B1']\n",
    "ss['BPMWF.A1R1.B1']\n",
    "td = dffff * dfcopy.iloc[0]\n",
    "td2 = td[(td>1.0)| (td< -1.0)]\n",
    "td3 = td2.dropna(axis=1)\n",
    "td2['BPM.11R5.B1']\n",
    "td2.dropna(axis=1,how='all')['BPM.11R5.B1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(fill4696.bpmdf.columns).index('BPM.11R5.B1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0,max=len(bpmr5test)+len(bpmr5test) )\n",
    "display(f)\n",
    "\n",
    "fig = plt.figure(figsize=(18,20))\n",
    "ax = fig.add_subplot(211)\n",
    "\n",
    "s1 = np.array([float(tfsbpm[tfsbpm['NAME']==n]['S'].values[0]) for n in names])\n",
    "max1 = len(bpml5test)\n",
    "nn = 1000\n",
    "step = 20\n",
    "for i in range(0,len(bpml5test.tail(nn)),step):\n",
    "    data = np.array([bpml5test[n][max1-nn+i] for n in names])\n",
    "    plt.scatter(s1,data)\n",
    "    plt.plot(s1,data)\n",
    "    f.value = i\n",
    "plt.plot((0,500),(500,500),'k-')\n",
    "plt.plot((0,500),(-500,-500),'k-')\n",
    "plt.plot((0,500),(-3000,-3000),'k-')\n",
    "plt.plot((0,500),(-3500,-3500),'k-')\n",
    "plt.plot((0,500),(0,0),'k-')\n",
    "plt.grid()\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(-10000,5000)\n",
    "ax.set_xticks(np.arange(0,500,100))\n",
    "ax.set_xticks(np.arange(0,500,10),minor=True)\n",
    "ax.set_yticks(np.arange(-10000,5000,2000))\n",
    "ax.set_yticks(np.arange(-10000,5000,500),minor=True)\n",
    "ax.grid(which='minor',alpha=0.2)\n",
    "plt.xlabel('s [m from IP5]',fontsize=16.0)\n",
    "plt.ylabel('x [um]')\n",
    "plt.title('BPM orbits Horizontal left of IP5 - fill 4707 ')\n",
    "ax.text(100,4000, 'Each line (colour) is at a different timestamp.')\n",
    "ax.annotate('roughly 0.5 mm below \\n 3mm from bump',xy=(440,-3400),xytext=(400,-5000),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.5))\n",
    "ax.plot([440],[500],'o')\n",
    "ax.annotate('Expected with 0.5 mm bump',xy=(440,500),xytext=(400,2500),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "max2 = len(bpmr5test)\n",
    "s2 = np.array([float(tfsbpmr[tfsbpmr['NAME']==n]['S'].values[0]) for n in namesr])\n",
    "for i in range(0,len(bpmr5test.tail(nn)),step):\n",
    "    data =  np.array([bpmr5test[n][max2-nn+i] for n in namesr])\n",
    "    ax2.scatter(s2,data)\n",
    "    ax2.plot(s2,data)\n",
    "    f.value = f.value +1 \n",
    "plt.plot((0,500),(500,500),'k-')\n",
    "plt.plot((0,500),(-500,-500),'k-')\n",
    "plt.plot((0,500),(-3000,-3000),'k-')\n",
    "plt.plot((0,500),(-3500,-3500),'k-')\n",
    "plt.plot((0,500),(0,0),'k-')\n",
    "plt.grid()\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(-10000,5000)\n",
    "ax2.set_xticks(np.arange(0,500,100))\n",
    "ax2.set_xticks(np.arange(0,500,10),minor=True)\n",
    "ax2.set_yticks(np.arange(-10000,5000,2000))\n",
    "ax2.set_yticks(np.arange(-10000,5000,500),minor=True)\n",
    "ax2.grid(which='minor',alpha=0.2)\n",
    "ax2.annotate('roughly 0.5 mm above \\n 3mm from bump',xy=(433,-2650),xytext=(400,-5000),\n",
    "            arrowprops=dict(facecolor='red',shrink=0.2))\n",
    "plt.xlabel('s [m from IP5]',fontsize=16.0)\n",
    "plt.ylabel('x [um]')\n",
    "plt.title('BPM orbits Horizontal right of IP5  - fill 4707 ')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('Fill4707IP5bpm.png',format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0,max=len(bpml5) )\n",
    "display(f)\n",
    "f.value=0\n",
    "fig = plt.figure(figsize=(18,20))\n",
    "mymap = plt.get_cmap('jet')\n",
    "norm = plt.Normalize()\n",
    "norm.autoscale(np.linspace(0,len(bpml5),len(bpml5)))\n",
    "for i in range(len(bpml5)):\n",
    "    plt.scatter(bpml5['BPM.7L5.B2'][i],bpml5['BPM.11L5.B2'][i],color=mymap(float(i)/len(bpml5)))\n",
    "    f.value = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe mask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfex = pd.DataFrame({'AAA' :[4,5,6,7],'BBB':[10,20,30,40],'CCC':[100,50,-30,-50]});dfex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfex_mask = pd.DataFrame({'AAA':[True] *4,'BBB':[False]*4,'CCC':[True,False]*2});dfex_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfex.where(dfex_mask,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfex.where(dfex_mask,0).plot(x='AAA',y='CCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfex.loc[(dfex['BBB']<=0) | (dfex['CCC'] >0),'AAA']=0.1;dfex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pf = pd.Panel({'dfs':tfsbpmr,'dfbpm':bpmr5})\n",
    "pf.ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb = tfs[tfs[\"NAME\"]=='MQ.11L5.B2']\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%save -f TimberGetDataClass.py 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CTE(object):\n",
    "    intensityout  = 'intensity.out'\n",
    "    emittanceout  = 'emittance.out'\n",
    "    ibsout        = 'ibs.out'\n",
    "    luminosityout = 'luminosity.out'\n",
    "    oldheaders = ['sim.turn', 't(hours)', \n",
    "               'N1_macro', 'N1_real', 'NlostLum1', 'Sum', \n",
    "               'NlostDebunch1','Sum.1', 'NLostBet1', 'Sum.2', 'NlostMom1', 'Sum.3', \n",
    "               'N2_macro', 'N2_real', 'NlostLum2','Sum.4', \n",
    "               'NlostDebunch2', 'SumNLostBet2', 'Sum.5', 'NlostMom2', 'Sum.6','']\n",
    "\n",
    "    oldlumiheader = ['sim.turn','t(hours)','L(cm^-2 s^-1)' ,'reduction factor','Beta']\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self.intensity, self.emit, self.ibs, self.lumi = self.loaddata()\n",
    "        self.macropartconv =  self.intensity['N1_real'].iloc[0]/self.intensity['N1_macro'].iloc[0]\n",
    "        \n",
    "    def loaddata(self):\n",
    "        intensfile    = self.path + '/' + self.intensityout\n",
    "        emitfile      = self.path + '/' + self.emittanceout\n",
    "        lumifile      = self.path + '/' + self.luminosityout\n",
    "        ibsfile       = self.path + '/' + self.ibsout\n",
    "        \n",
    "        intensitysimdata = pd.read_csv(intensfile,skiprows=[0,1],names=self.oldheaders,\n",
    "                                       delim_whitespace=True,index_col=None)\n",
    "        emittancesimdata = pd.read_csv(emitfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
    "        ibssimdata       = pd.read_csv(ibsfile,skiprows=[1],delim_whitespace=True,index_col=None)\n",
    "        lumisimdata      = pd.read_csv(lumifile,skiprows=[0,1],delim_whitespace=True,\n",
    "                                       names=self.oldlumiheader,index_col=None)\n",
    "        return intensitysimdata,emittancesimdata,ibssimdata,lumisimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%save -f CTEGetDataClass.py 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccte = CTE('/afs/cern.ch/work/t/tomerten/CTEJOBS/HI2016/Stableb4leveled/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccte.intensity.plot(x='t(hours)',y='N1_real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(fn1,'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    linenumber=1\n",
    "    try:\n",
    "        for row in reader:\n",
    "            linenumber +=1\n",
    "    except Exception as e:\n",
    "        print (('Error in line %d: %s %s  '% (linenumber,str(type(e)),e.message)))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
